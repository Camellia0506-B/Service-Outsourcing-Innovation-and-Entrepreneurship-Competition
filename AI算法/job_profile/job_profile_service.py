"""
Â≤ó‰ΩçÁîªÂÉèÊúçÂä°Ê®°Âùó v3 - Êï∞ÊçÆÈõÜ‰ºòÂÖàÁ≠ñÁï•
=============================================
ÁîüÊàêÁ≠ñÁï•Ôºö
  „Äê‰ºòÂÖà„ÄëÊï∞ÊçÆÈõÜJDÂàÜÊûêÔºö‰ªéCSVÊèêÂèñÂåπÈÖçÂ≤ó‰ΩçÁöÑËÅå‰ΩçÊèèËø∞(JD)ÔºåÂñÇÁªôÊ®°ÂûãÂàÜÊûêÊèêÁÇº
  „ÄêÂÖúÂ∫ï„ÄëÊ®°ÂûãÁü•ËØÜÁîüÊàêÔºöÊï∞ÊçÆÈõÜÊó†ÂåπÈÖçÊï∞ÊçÆÊó∂ÔºåÁî±Ê®°ÂûãÂá≠Ë°å‰∏öËÆ§Áü•ÁîüÊàê

‰∏é‰∏ä‰∏ÄÁâàÊú¨ÁöÑÊ†∏ÂøÉÂå∫Âà´Ôºö
  - ‰πãÂâçÔºö‰ªéCSVÂè™ÊèêÂèñËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏3‰∏™Â≠óÊÆµÔºàËæÖÂä©‰ø°ÊÅØÔºâ
  - Áé∞Âú®Ôºö‰ªéCSVÊèêÂèñÂÆåÊï¥ËÅå‰ΩçÊèèËø∞JDÔºà‰∏ªË¶Å‰ø°ÊÅØÊ∫êÔºâÔºåÊ®°ÂûãÂü∫‰∫éÁúüÂÆûJDÊèêÁÇºÁîªÂÉè

CSVÂ≠óÊÆµËØ¥ÊòéÔºàÊù•Ëá™Ê±ÇËÅåÂ≤ó‰Ωç‰ø°ÊÅØÊï∞ÊçÆ.csvÔºâÔºö
  ËÅå‰Ωç‰ª£Á†Å / ËÅå‰ΩçÂêçÁß∞ / Â∑•‰ΩúÂú∞ÂùÄ / Ëñ™ËµÑËåÉÂõ¥ /
  ‰ºÅ‰∏öÊÄßË¥® / ÂÖ¨Âè∏ÂÖ®Áß∞ / ‰∫∫ÂëòËßÑÊ®° / ÊâÄÂ±ûË°å‰∏ö / ËÅå‰ΩçÊèèËø∞ / ÂÖ¨Âè∏ÁÆÄ‰ªã

ÂØπÂ∫îAPIÔºö
  4.1 POST /job/profiles
  4.2 POST /job/profile/detail
  4.4 POST /job/ai-generate-profile
"""

import csv
import json
import os
import re
from datetime import datetime
from typing import Optional

import yaml
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate

from utils.logger_handler import logger
from utils.path_tool import get_abs_path


# ========== Âä†ËΩΩÈÖçÁΩÆ ==========
def _load_job_profile_config() -> dict:
    config_path = get_abs_path("config/job_profile.yml")
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.load(f, Loader=yaml.FullLoader)


job_profile_conf = _load_job_profile_config()


# ========== Â∑•ÂÖ∑ÂáΩÊï∞ ==========

def _load_prompt(prompt_key: str) -> str:
    prompts_config_path = get_abs_path("config/prompts.yml")
    with open(prompts_config_path, "r", encoding="utf-8") as f:
        prompts_conf = yaml.load(f, Loader=yaml.FullLoader)
    path = get_abs_path(prompts_conf[prompt_key])
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def _ensure_store_dir() -> str:
    store_path = get_abs_path(job_profile_conf["job_profiles_store"])
    os.makedirs(os.path.dirname(store_path), exist_ok=True)
    return store_path


def _load_profiles_store() -> dict:
    """Áõ¥Êé•‰ªé CSV Âä†ËΩΩÂ≤ó‰ΩçÊï∞ÊçÆÔºå‰∏çÂÜçËØªÂèñ profiles.json„ÄÇ"""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        csv_path = os.path.join(base_dir, "..", "data", "Ê±ÇËÅåÂ≤ó‰Ωç‰ø°ÊÅØÊï∞ÊçÆ.csv")
        csv_path = os.path.normpath(csv_path)
        print(f"CSVË∑ØÂæÑ: {csv_path}, Â≠òÂú®: {os.path.exists(csv_path)}")
        if not os.path.exists(csv_path):
            logger.warning(f"[ProfileStore] CSV ‰∏çÂ≠òÂú®: {csv_path}ÔºåËøîÂõûÁ©∫Â≠óÂÖ∏")
            return {}
        profiles = {}
        with open(csv_path, encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for i, row in enumerate(reader):
                job_id = row.get("ËÅå‰ΩçÁºñÂè∑") or f"job_{i+1:04d}"
                job_name = row.get("ËÅå‰ΩçÂêçÁß∞", "").strip() or f"Â≤ó‰Ωç_{i+1}"
                profiles[job_id] = {
                    "job_id": job_id,
                    "job_name": job_name,
                    "basic_info": {
                        "industry": row.get("ÊâÄÂ±ûË°å‰∏ö", ""),
                        "level_range": ["ÂàùÁ∫ß"],
                        "salary_range": row.get("Ëñ™ËµÑËåÉÂõ¥", ""),
                        "location": row.get("Â∑•‰ΩúÂú∞ÂùÄ", ""),
                        "company": row.get("ÂÖ¨Âè∏ÂÖ®Áß∞", ""),
                        "company_scale": row.get("‰∫∫ÂëòËßÑÊ®°", ""),
                        "company_type": row.get("‰ºÅ‰∏öÊÄßË¥®", ""),
                    },
                    "description": row.get("ËÅå‰ΩçÊèèËø∞", ""),
                    "company_intro": row.get("ÂÖ¨Âè∏ÁÆÄ‰ªã", ""),
                    "market_analysis": {"demand_score": 75, "growth_trend": "Á®≥ÂÆö"},
                }
        print(f"CSVÂä†ËΩΩÊàêÂäü: {len(profiles)} Êù°")
        logger.info(f"[ProfileStore] Â∑≤‰ªé CSV Âä†ËΩΩ {len(profiles)} Êù°Â≤ó‰ΩçÊï∞ÊçÆ: {csv_path}")
        return profiles
    except Exception as e:
        print(f"CSVÂä†ËΩΩÂ§±Ë¥•: {e}")
        logger.warning(f"[ProfileStore] CSV Âä†ËΩΩÂ§±Ë¥•: {e}", exc_info=True)
        return {}


def _save_profiles_store(profiles: dict):
    # Âè™ÂÖÅËÆ∏ÂÜôÂÖ•ÁúüÂÆûÂ≠óÂÖ∏ÔºåÈò≤Ê≠¢ Mock ÂØπË±°ÊàñÈùûÊ≥ïÊï∞ÊçÆÊçüÂùèÊñá‰ª∂
    if not isinstance(profiles, dict):
        logger.error(f"[ProfileStore] ÊãíÁªùÂÜôÂÖ•ÈùûdictÂØπË±°: {type(profiles)}")
        return
    store_path = _ensure_store_dir()
    with open(store_path, "w", encoding="utf-8") as f:
        json.dump(profiles, f, ensure_ascii=False, indent=2)


def _normalize_profile(p: dict) -> dict:
    """
    ÂÖúÂ∫ïÂ≠óÊÆµÊò†Â∞ÑÔºöÁ°Æ‰øùÁîªÂÉèËøîÂõûÂ≠óÊÆµ‰∏éAPIÊñáÊ°£4.2ÂÆåÂÖ®‰∏ÄËá¥„ÄÇ
    ÂêåÊó∂ÂÖºÂÆπÊóßÊ†ºÂºèÁîªÂÉèÔºà‰ΩøÁî®ÊóßÂ≠óÊÆµÂêçÁîüÊàêÁöÑÔºâ„ÄÇ
    Âè™ÂÅöË°•ÂÖÖÂíåÊò†Â∞ÑÔºå‰∏çÂà†Èô§ÂéüÊúâÂ≠óÊÆµÔºå‰øùÊåÅÂêëÂêéÂÖºÂÆπ„ÄÇ
    """
    import copy
    p = copy.deepcopy(p)
    bi = p.get("basic_info", {})

    # basic_info.levelÔºöÊñáÊ°£Ë¶ÅÊ±ÇÂçïÂ≠óÁ¨¶‰∏≤ÔºåÂÖúÂ∫ïÂèñ level_range[0]
    if "level" not in bi:
        lr = bi.get("level_range", [])
        bi["level"] = lr[0] if lr else "ÂàùÁ∫ß"

    # basic_info.avg_salaryÔºöÊñáÊ°£Ë¶ÅÊ±ÇÂçïÂ≠óÁ¨¶‰∏≤ÔºõCSV ‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÊóßÁîªÂÉè‰∏∫ dict
    if "avg_salary" not in bi:
        sr = bi.get("salary_range")
        bi["avg_salary"] = sr.get("junior", "") if isinstance(sr, dict) else (sr or "")

    # basic_info.company_scalesÔºöÊñáÊ°£Ë¶ÅÊ±ÇÂ≠òÂú®Ê≠§Â≠óÊÆµ
    if "company_scales" not in bi:
        bi["company_scales"] = ["100-500‰∫∫", "500-2000‰∫∫", "2000‰∫∫‰ª•‰∏ä"]

    p["basic_info"] = bi

    # requirements.basic_requirements.gpaÔºöÊñáÊ°£Ë¶ÅÊ±ÇÂ≠òÂú®Ê≠§Â≠óÊÆµ
    br = p.get("requirements", {}).get("basic_requirements", {})
    if "gpa" not in br:
        br["gpa"] = {"min_requirement": "3.0/4.0", "preferred": "3.5/4.0‰ª•‰∏ä", "weight": 0.05}
        if "basic_requirements" in p.get("requirements", {}):
            p["requirements"]["basic_requirements"] = br

    # market_analysis.hottest_citiesÔºöÊñáÊ°£Ë¶ÅÊ±Ç {city, job_count}ÔºåÊóßÊ†ºÂºèÊòØ {city, demand_level}
    cities = p.get("market_analysis", {}).get("hottest_cities", [])
    for c in cities:
        if "job_count" not in c:
            # demand_level ‚Üí job_count ‰º∞ÁÆóÊò†Â∞Ñ
            dm = c.pop("demand_level", "‰∏≠")
            c["job_count"] = {"ÊûÅÈ´ò": 2000, "È´ò": 1200, "‰∏≠": 600, "‰Ωé": 200}.get(dm, 600)
    if "market_analysis" in p:
        p["market_analysis"]["hottest_cities"] = cities

    # career_path.current_levelÔºöÊñáÊ°£Ë¶ÅÊ±ÇÊ≠§Â≠óÊÆµÂêçÔºåÊóßÂ≠óÊÆµÂêçÊòØ entry_level
    cp = p.get("career_path", {})
    if "current_level" not in cp and "entry_level" in cp:
        cp["current_level"] = cp.pop("entry_level")
        p["career_path"] = cp

    return p


def _extract_json(text: str) -> dict:
    """‰ªéÊ®°ÂûãËæìÂá∫‰∏≠ÊèêÂèñJSONÔºåÂÖºÂÆπmarkdown‰ª£Á†ÅÂùóÂåÖË£π"""
    text = text.strip()
    text = re.sub(r"^```json\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"^```\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"\s*```$", "", text, flags=re.MULTILINE)
    text = text.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        match = re.search(r"\{[\s\S]+\}", text)
        if match:
            try:
                return json.loads(match.group())
            except Exception:
                pass
        raise ValueError(f"Ê®°ÂûãËæìÂá∫Êó†Ê≥ïËß£Êûê‰∏∫JSONÔºåÁâáÊÆµ: {text[:300]}")


def _normalize_job_profile(profile: dict) -> dict:
    """Á°Æ‰øùÁîªÂÉèÂåÖÂê´ÂâçÁ´ØÂ±ïÁ§∫ÊâÄÈúÄÁöÑÊâÄÊúâÂ≠óÊÆµÁªìÊûÑÔºåÁº∫Â§±Êó∂Áî®Á©∫ÂÄºÂÖúÂ∫ïÔºåÈÅøÂÖçÈ°µÈù¢ÂÖ®Á©∫"""
    if not isinstance(profile, dict):
        return {}
    # core_skills
    core = profile.get("core_skills")
    if not isinstance(core, dict):
        core = {}
    for list_key in ("professional", "tools", "certificates"):
        if not isinstance(core.get(list_key), list):
            core[list_key] = []
    soft = core.get("soft_skills")
    if not isinstance(soft, dict):
        soft = {}
    for key in ("innovation", "learning", "pressure", "communication", "internship"):
        if key not in soft or not (soft[key] and str(soft[key]).strip()):
            soft[key] = soft.get(key) or "ÊöÇÊó†ÊèèËø∞"
    core["soft_skills"] = soft
    profile["core_skills"] = core
    # reality_check
    rc = profile.get("reality_check")
    if not isinstance(rc, dict):
        rc = {}
    if not isinstance(rc.get("pros"), list):
        rc["pros"] = []
    if not isinstance(rc.get("cons"), list):
        rc["cons"] = []
    for key in ("misconceptions", "suitable_for", "not_suitable_for"):
        if key not in rc or not (rc[key] and str(rc[key]).strip()):
            rc[key] = rc.get(key) or "ÊöÇÊó†"
    profile["reality_check"] = rc
    # entry_path
    ep = profile.get("entry_path")
    if not isinstance(ep, dict):
        ep = {}
    if not isinstance(ep.get("key_projects"), list):
        ep["key_projects"] = []
    ep.setdefault("fresh_grad", ep.get("fresh_grad") or "")
    ep.setdefault("timeline", ep.get("timeline") or "")
    profile["entry_path"] = ep
    # ai_summary
    if not (profile.get("ai_summary") and str(profile.get("ai_summary")).strip()):
        profile["ai_summary"] = profile.get("ai_summary") or profile.get("summary") or ""
    return profile


def _old_profile_to_new(profile: dict) -> dict:
    """
    Ëã•Ê®°ÂûãËøîÂõûÊóßÁâà job_profileÔºàÂê´ basic_info/requirements Á≠âÔºâÔºå
    ËΩ¨Êç¢‰∏∫ÂâçÁ´Ø‰∏é 4.5 Êé•Âè£Á∫¶ÂÆöÁöÑÊñ∞ÁªìÊûÑÔºöcore_skills„ÄÅreality_check„ÄÅentry_path„ÄÅai_summary„ÄÇ
    """
    if not isinstance(profile, dict):
        return profile
    # Â∑≤ÊúâÊñ∞ÁªìÊûÑÔºàÂê´ core_skills ÁöÑ professional/tools Êàñ reality_checkÔºâÂàô‰∏çÂÜçËΩ¨Êç¢
    core = profile.get("core_skills")
    if isinstance(core, dict) and ("professional" in core or "tools" in core):
        return profile
    if isinstance(profile.get("reality_check"), dict) and isinstance(profile.get("entry_path"), dict):
        return profile
    basic = profile.get("basic_info") or {}
    reqs = profile.get("requirements") or {}
    basic_req = reqs.get("basic_requirements") or {}
    career = profile.get("career_development") or {}
    prof_skills = reqs.get("professional_skills") or {}
    core_skills_old = reqs.get("core_skills") or {}

    # ‰∏ì‰∏öÊäÄËÉΩÔºöÊóßÁâà programming_languages + domain_knowledge ÁöÑ skillÔºåÊàñ core_skills.technical_skills
    professional = list(core_skills_old.get("technical_skills") or [])
    if not professional:
        for lang in prof_skills.get("programming_languages") or []:
            s = lang.get("skill") if isinstance(lang, dict) else lang
            if s:
                professional.append(s if isinstance(s, str) else str(s))
        for dom in prof_skills.get("domain_knowledge") or []:
            s = dom.get("skill") if isinstance(dom, dict) else dom
            if s:
                professional.append(s if isinstance(s, str) else str(s))

    # Â∑•ÂÖ∑
    tools = list(core_skills_old.get("tools") or [])
    if not tools:
        for t in prof_skills.get("frameworks_tools") or []:
            s = t.get("skill") if isinstance(t, dict) else t
            if s:
                tools.append(s if isinstance(s, str) else str(s))

    # ËØÅ‰π¶
    certs = list(basic_req.get("certifications") or [])
    if not certs and basic_req.get("education"):
        edu = basic_req["education"]
        if isinstance(edu, dict) and edu.get("level"):
            certs = [edu.get("level", "")]
        elif isinstance(edu, str):
            certs = [edu]

    # ËΩØÊäÄËÉΩÔºöÊóßÁâàÂèØËÉΩÊòØÂàóË°®ÊàñÂ≠óÂÖ∏
    soft_list = core_skills_old.get("soft_skills")
    if isinstance(soft_list, list):
        soft_list = [str(s) for s in soft_list]
    elif not isinstance(soft_list, list):
        soft_list = []
    def _find_soft(keywords):
        for s in soft_list:
            if any(kw in str(s) for kw in keywords):
                return s
        return "ÊöÇÊó†ÊèèËø∞"
    soft_skills = {
        "innovation": _find_soft(["ÂàõÊñ∞"]),
        "learning": _find_soft(["Â≠¶‰π†"]),
        "pressure": _find_soft(["Âéã", "ÊäóÂéã"]),
        "communication": _find_soft(["Ê≤üÈÄö", "Âçè‰Ωú"]),
        "internship": (basic_req.get("experience") or career.get("experience") or "ÊöÇÊó†ÊèèËø∞"),
    }
    if isinstance(soft_skills["internship"], dict):
        soft_skills["internship"] = str(soft_skills["internship"]) or "ÊöÇÊó†ÊèèËø∞"

    profile["industry"] = basic.get("industry") or profile.get("industry") or ""
    profile["salary_range"] = basic.get("avg_salary") or profile.get("salary_range") or ""
    profile["demand_score"] = profile.get("demand_score") or (profile.get("market_analysis") or {}).get("demand_score") or 85
    profile["trend"] = (profile.get("market_info") or {}).get("trend") or (profile.get("market_analysis") or {}).get("trend") or "‰∏äÂçá"
    profile["trend_desc"] = (profile.get("market_info") or {}).get("trend_desc") or ""

    profile["core_skills"] = {
        "professional": professional,
        "tools": tools,
        "certificates": certs,
        "soft_skills": soft_skills,
    }
    profile["reality_check"] = {
        "pros": list(career.get("advantages") or []),
        "cons": list(career.get("challenges") or []),
        "suitable_for": profile.get("suitable_for") or career.get("suitable_for") or "ÊöÇÊó†",
        "not_suitable_for": profile.get("not_suitable_for") or career.get("not_suitable_for") or "ÊöÇÊó†",
        "misconceptions": profile.get("misconceptions") or "ÊöÇÊó†",
    }
    profile["entry_path"] = {
        "fresh_grad": career.get("entry_advice") or profile.get("entry_advice") or "",
        "key_projects": list(career.get("key_projects") or []),
        "timeline": career.get("timeline") or "",
    }
    profile["ai_summary"] = (profile.get("description") or profile.get("ai_summary") or profile.get("summary") or "").strip() or "AIÂ∑≤Ê†πÊçÆÂ≤ó‰ΩçÊï∞ÊçÆÁîüÊàêÁîªÂÉèÊëòË¶Å„ÄÇ"
    return profile


# ========== Êï∞ÊçÆÈõÜÊèêÂèñÂô®ÔºàÊï∞ÊçÆ‰ºòÂÖàÁ≠ñÁï•ÁöÑÊ†∏ÂøÉÔºâ==========

class CsvDataExtractor:
    """
    ‰ªéCSVÊï∞ÊçÆÈõÜ‰∏≠ÊèêÂèñÂ≤ó‰ΩçÁöÑÂÆåÊï¥‰ø°ÊÅØ„ÄÇ

    Á≠ñÁï•ËØ¥ÊòéÔºö
      - ÊèêÂèñÂÆåÊï¥ÁöÑËÅå‰ΩçÊèèËø∞(JD)ÊñáÊú¨Ôºå‰Ωú‰∏∫Ê®°ÂûãÂàÜÊûêÁöÑ‰∏ªË¶ÅÂéüÊñô
      - ÊèêÂèñËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏Á≠âÁªìÊûÑÂåñ‰ø°ÊÅØ‰Ωú‰∏∫ËæÖÂä©
      - ÊúâÊï∞ÊçÆ ‚Üí Âü∫‰∫éÁúüÂÆûJDÁîüÊàêÁîªÂÉèÔºàÊï∞ÊçÆÈ©±Âä®Ôºâ
      - Êó†Êï∞ÊçÆ ‚Üí Ê†áËÆ∞‰∏∫"Êó†ÂåπÈÖçÊï∞ÊçÆ"Ôºå‰∫§Áî±Ê®°ÂûãÁü•ËØÜÁîüÊàêÔºàÊ®°ÂûãÂÖúÂ∫ïÔºâ
    """

    # CSVÂêÑÂ≠óÊÆµÂêçÔºà‰∏éÂÆûÈôÖÊñá‰ª∂‰øùÊåÅ‰∏ÄËá¥Ôºâ
    FIELD_NAME      = "ËÅå‰ΩçÂêçÁß∞"
    FIELD_ADDRESS   = "Â∑•‰ΩúÂú∞ÂùÄ"
    FIELD_SALARY    = "Ëñ™ËµÑËåÉÂõ¥"
    FIELD_COMPANY   = "ÂÖ¨Âè∏ÂÖ®Áß∞"
    FIELD_NATURE    = "‰ºÅ‰∏öÊÄßË¥®"
    FIELD_SCALE     = "‰∫∫ÂëòËßÑÊ®°"
    FIELD_INDUSTRY  = "ÊâÄÂ±ûË°å‰∏ö"
    FIELD_JD        = "ËÅå‰ΩçÊèèËø∞"

    def __init__(self):
        self.data_path = get_abs_path(job_profile_conf["job_data_path"])
        self._all_rows: Optional[list] = None

    def _load_all(self) -> list:
        if self._all_rows is not None:
            return self._all_rows
        if not os.path.exists(self.data_path):
            logger.warning(f"[CsvDataExtractor] CSVÊñá‰ª∂‰∏çÂ≠òÂú®: {self.data_path}")
            self._all_rows = []
            return []
        rows = []
        with open(self.data_path, "r", encoding="utf-8-sig") as f:
            for row in csv.DictReader(f):
                rows.append(row)
        self._all_rows = rows
        logger.info(f"[CsvDataExtractor] Âä†ËΩΩCSV: {len(rows)}Êù°")
        return rows

    def search(self, keywords: list[str], max_count: int = 10) -> list[dict]:
        """
        ÂÖ≥ÈîÆËØçÂåπÈÖçËÅå‰ΩçÂêçÁß∞ÔºåËøîÂõûÂåπÈÖçÂà∞ÁöÑÂÆåÊï¥Ë°åÊï∞ÊçÆÔºàÂê´JDÔºâ„ÄÇ
        Â§ßÂ∞èÂÜô‰∏çÊïèÊÑüÔºå‰ªªÊÑèÂÖ≥ÈîÆËØçÂëΩ‰∏≠Âç≥ÁÆóÂåπÈÖç„ÄÇ
        """
        all_rows = self._load_all()
        keywords_lower = [kw.lower() for kw in keywords]
        matched = []
        for row in all_rows:
            name = row.get(self.FIELD_NAME, "").lower()
            if any(kw in name for kw in keywords_lower):
                matched.append(row)
            if len(matched) >= max_count:
                break
        return matched

    def build_jd_block(self, matched_rows: list[dict]) -> str:
        """
        Â∞ÜÂåπÈÖçÂà∞ÁöÑËÅå‰ΩçÊï∞ÊçÆÁªÑË£ÖÊàêÁªìÊûÑÂåñÊñáÊú¨ÂùóÔºå‰æõÊèêÁ§∫ËØçÊ≥®ÂÖ•„ÄÇ
        ÊØèÊù°Êï∞ÊçÆÂåÖÂê´ÔºöËÅå‰ΩçÂêçÁß∞ + Ëñ™ËµÑ + Ë°å‰∏ö + ËÅå‰ΩçÊèèËø∞(ÂÆåÊï¥)
        """
        if not matched_rows:
            return ""  # Ë∞ÉÁî®ÊñπÊ£ÄÊü•Á©∫Â≠óÁ¨¶‰∏≤ÂÜ≥ÂÆöËµ∞Âì™Êù°ÂàÜÊîØ

        blocks = []
        for i, row in enumerate(matched_rows, 1):
            jd_text = row.get(self.FIELD_JD, "").strip()
            # Êà™Êñ≠ËøáÈïøÁöÑJDÔºàÈò≤Ê≠¢promptËøáÂ§ßÔºâÔºå‰øùÁïôÂâç1500Â≠ó
            if len(jd_text) > 1500:
                jd_text = jd_text[:1500] + "‚Ä¶‚Ä¶ÔºàÊà™Êñ≠Ôºâ"
            block = (
                f"„ÄêÊ†∑Êú¨{i}„Äë\n"
                f"  ËÅå‰ΩçÂêçÁß∞Ôºö{row.get(self.FIELD_NAME, '')}\n"
                f"  Ëñ™ËµÑËåÉÂõ¥Ôºö{row.get(self.FIELD_SALARY, 'Êú™Áü•')}\n"
                f"  ÊâÄÂ±ûË°å‰∏öÔºö{row.get(self.FIELD_INDUSTRY, 'Êú™Áü•')}\n"
                f"  ‰ºÅ‰∏öËßÑÊ®°Ôºö{row.get(self.FIELD_SCALE, 'Êú™Áü•')}\n"
                f"  ËÅå‰ΩçÊèèËø∞Ôºö\n{jd_text}"
            )
            blocks.append(block)

        return "\n\n".join(blocks)

    def get_market_meta(self, matched_rows: list[dict]) -> dict:
        """ÊèêÂèñÁªìÊûÑÂåñÂ∏ÇÂú∫ÂÖÉÊï∞ÊçÆÔºàËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏ÔºâÔºåÁî®‰∫éÁîªÂÉèÁöÑmarket_analysisÂ≠óÊÆµ"""
        if not matched_rows:
            return {"salaries": [], "cities": [], "companies": [], "industries": []}
        return {
            "salaries":   list({r.get(self.FIELD_SALARY, "") for r in matched_rows if r.get(self.FIELD_SALARY)}),
            "cities":     list({r.get(self.FIELD_ADDRESS, "").split("¬∑")[0] for r in matched_rows if r.get(self.FIELD_ADDRESS)}),
            "companies":  list({r.get(self.FIELD_COMPANY, "") for r in matched_rows if r.get(self.FIELD_COMPANY)})[:5],
            "industries": list({r.get(self.FIELD_INDUSTRY, "") for r in matched_rows if r.get(self.FIELD_INDUSTRY)}),
        }


# ========== Â≤ó‰ΩçÁîªÂÉèÁîüÊàêÊúçÂä° ==========

class JobProfileService:
    """
    Â≤ó‰ΩçÁîªÂÉèÁîüÊàê‰∏éÁÆ°ÁêÜÊúçÂä°

    ÁîüÊàêÁ≠ñÁï•ÔºàÊï∞ÊçÆÈõÜ‰ºòÂÖàÔºâÔºö
      ÊúâÂåπÈÖçJD ‚Üí Ê®°ÂûãÂü∫‰∫éÁúüÂÆûJDÊèêÁÇºÊ†áÂáÜÂåñÁîªÂÉè
      Êó†ÂåπÈÖçJD ‚Üí Ê®°ÂûãÂá≠Ë°å‰∏öËÆ§Áü•ÁîüÊàêÔºàÂÖúÂ∫ïÔºâ
    """

    def __init__(self):
        self.extractor = CsvDataExtractor()
        self.profiles_store = _load_profiles_store()
        self.model = self._init_model()

    def _init_model(self):
        try:
            from model.factory import chat_model
            return chat_model
        except ImportError:
            from langchain_community.chat_models.tongyi import ChatTongyi
            from utils.config_handler import rag_conf
            return ChatTongyi(model=rag_conf["chat_model_name"])

    def _build_chain(self):
        prompt_text = _load_prompt("job_profile_prompt_path")
        template = PromptTemplate.from_template(prompt_text)
        return template | self.model | StrOutputParser()

    # ===================================================
    # Ê†∏ÂøÉÔºöÁîüÊàêÂçï‰∏™Â≤ó‰ΩçÁîªÂÉè
    # ===================================================
    def generate_profile(self, job_config: dict) -> dict:
        """
        ÁîüÊàêÂ≤ó‰ΩçÁîªÂÉèÔºö
          1. ‰ªéCSVÊêúÁ¥¢ÂåπÈÖçÁöÑJDÊï∞ÊçÆ
          2. ÊúâÊï∞ÊçÆ ‚Üí Ê≥®ÂÖ•JDÊñáÊú¨ÔºåËÆ©Ê®°ÂûãÂü∫‰∫éÁúüÂÆûÊï∞ÊçÆÊèêÁÇº
             Êó†Êï∞ÊçÆ ‚Üí Ê≥®ÂÖ•ÊòéÁ°ÆÊèêÁ§∫ÔºåËÆ©Ê®°ÂûãÂá≠Áü•ËØÜÁîüÊàêÔºàÂÖúÂ∫ïÔºâ
          3. Ë∞ÉÁî®Ê®°ÂûãÔºåËß£ÊûêËæìÂá∫JSON
          4. Ë°•ÂÖÖÂÖÉÊï∞ÊçÆÂπ∂Â≠òÂÇ®
        """
        job_id    = job_config["job_id"]
        job_name  = job_config["name"]
        category  = job_config.get("category", "")
        keywords  = job_config.get("csv_keywords", [job_name])
        weights   = job_config.get("dimension_weights", {})
        max_count = job_profile_conf.get("max_csv_sample_per_job", 10)

        logger.info(f"[JobProfileService] ÂºÄÂßãÁîüÊàê: {job_name} ({job_id})")

        # Step 1: Ëé∑ÂèñJDÊï∞ÊçÆÔºà‰ºòÂÖà‰ΩøÁî®ÂâçÁ´Ø‰º†ÂÖ•ÔºåÂÖ∂Ê¨°CSVÊ£ÄÁ¥¢Ôºâ
        external_jds = job_config.get("external_jd_list", [])  # 4.4Êé•Âè£ÂâçÁ´Ø‰º†ÂÖ•

        if external_jds:
            # ‚òÖ ÂàÜÊîØA1ÔºöÂâçÁ´ØÁõ¥Êé•‰º†ÂÖ•JDÂàóË°®ÔºàAPIÊñáÊ°£4.4Ôºâ
            jd_texts = "\n\n".join(
                f"„ÄêJD {i+1}„Äë\n{jd}" for i, jd in enumerate(external_jds[:max_count])
            )
            jd_block    = jd_texts
            matched_rows = []
            market_meta  = {}
            logger.info(f"  ‰ΩøÁî®ÂâçÁ´Ø‰º†ÂÖ•JD: {len(external_jds)}Êù°")
        else:
            # ‚òÖ ÂàÜÊîØA2Ôºö‰ªéCSVÊï∞ÊçÆÈõÜÊ£ÄÁ¥¢
            matched_rows = self.extractor.search(keywords, max_count)
            jd_block     = self.extractor.build_jd_block(matched_rows)
            market_meta  = self.extractor.get_market_meta(matched_rows)
            logger.info(f"  CSVÊ£ÄÁ¥¢: {len(matched_rows)}Êù°ÂåπÈÖçÊï∞ÊçÆ")

        # Step 2: ÊûÑÂª∫Êï∞ÊçÆÊ≥®ÂÖ•ÊñáÊú¨Ôºà‰∏âÊù°ÂàÜÊîØÊ∏ÖÊô∞Ôºâ
        if external_jds:
            # ‚òÖ ÂâçÁ´Ø‰º†ÂÖ•JD
            data_section = (
                f"[Êï∞ÊçÆÊù•Ê∫êÔºöÂâçÁ´Ø‰º†ÂÖ•JD | Êù°Êï∞Ôºö{len(external_jds)}]\n"
                f"‰ª•‰∏ãÊòØË∞ÉÁî®Êñπ‰º†ÂÖ•ÁöÑÁúüÂÆûÊãõËÅòJDÔºåËØ∑‰∏•Ê†ºÂü∫‰∫éËøô‰∫õJDÂÜÖÂÆπÊèêÁÇºÂ≤ó‰ΩçÁîªÂÉèÔºå"
                f"‰∏çË¶ÅËá™Áî±ÂèëÊå•Ë∂ÖÂá∫JDËåÉÂõ¥ÁöÑÂÜÖÂÆπÔºö\n\n"
                f"{jd_block}"
            )
            data_source_label = f"ÂâçÁ´Ø‰º†ÂÖ•JDÂàÜÊûêÔºà{len(external_jds)}Êù°Ê†∑Êú¨Ôºâ"
        elif jd_block:
            # ‚òÖ CSVÊ£ÄÁ¥¢Âà∞Êï∞ÊçÆ
            data_section = (
                f"[Êï∞ÊçÆÊù•Ê∫êÔºöÊï∞ÊçÆÈõÜ | ÂåπÈÖçÊù°Êï∞Ôºö{len(matched_rows)}]\n"
                f"‰ª•‰∏ãÊòØÊï∞ÊçÆÈõÜ‰∏≠Ê£ÄÁ¥¢Âà∞ÁöÑÁúüÂÆûÊãõËÅòJDÔºåËØ∑‰∏•Ê†ºÂü∫‰∫éËøô‰∫õJDÂÜÖÂÆπÊèêÁÇºÂ≤ó‰ΩçÁîªÂÉèÔºå"
                f"‰∏çË¶ÅËá™Áî±ÂèëÊå•Ë∂ÖÂá∫JDËåÉÂõ¥ÁöÑÂÜÖÂÆπÔºö\n\n"
                f"{jd_block}"
            )
            data_source_label = f"Êï∞ÊçÆÈõÜJDÂàÜÊûêÔºà{len(matched_rows)}Êù°Ê†∑Êú¨Ôºâ"
        else:
            # ‚òÖ Êó†‰ªª‰ΩïÊï∞ÊçÆÔºåÊ®°ÂûãÁü•ËØÜÂÖúÂ∫ï
            data_section = (
                f"[Êï∞ÊçÆÊù•Ê∫êÔºöÊ®°ÂûãÁü•ËØÜ | Êï∞ÊçÆÈõÜÊó†ÂåπÈÖç]\n"
                f"Êï∞ÊçÆÈõÜ‰∏≠Êú™Ê£ÄÁ¥¢Âà∞„Äê{job_name}„ÄëÁöÑÁõ∏ÂÖ≥ÊãõËÅòÊï∞ÊçÆ„ÄÇ\n"
                f"ËØ∑ÂÆåÂÖ®‰æùÊçÆ‰Ω†ÂØπ‰∏≠ÂõΩITË°å‰∏öÁöÑ‰∏ì‰∏öËÆ§Áü•ÔºåÊåâ2024-2025Âπ¥Â∏ÇÂú∫Ê†áÂáÜÁîüÊàêÁîªÂÉè„ÄÇ\n"
                f"Ëñ™ËµÑÂèÇÁÖß‰∏ÄÁ∫øÂüéÂ∏ÇÔºàÂåó‰∫¨/‰∏äÊµ∑/Ê∑±Âú≥/Êù≠Â∑ûÔºâË°åÊÉÖ„ÄÇ"
            )
            data_source_label = "Ê®°ÂûãË°å‰∏öÁü•ËØÜÁîüÊàêÔºàÊï∞ÊçÆÈõÜÊó†ÂåπÈÖçÔºâ"

        # Step 3: Ë∞ÉÁî®Ê®°Âûã
        chain = self._build_chain()
        raw_output = chain.invoke({
            "job_name":     job_name,
            "job_id":       job_id,
            "category":     category,
            "data_section": data_section,
            "dim_weights":  json.dumps(weights, ensure_ascii=False),
        })
        # Ë∞ÉËØïÔºöÊâìÂç∞ qwen ÂÆåÊï¥ËøîÂõûÂÜÖÂÆπÔºàStrOutputParser ‰∏ã raw_output Âç≥‰∏∫Ê®°ÂûãËæìÂá∫Â≠óÁ¨¶‰∏≤Ôºâ
        content = raw_output if isinstance(raw_output, str) else getattr(raw_output, "content", str(raw_output))
        print("=== qwenÂÆåÊï¥ËøîÂõû ===")
        print(content)
        print("=== ËøîÂõûÈïøÂ∫¶:", len(content), "===")

        # Step 4: Ëß£ÊûêJSON
        try:
            profile = _extract_json(raw_output)
        except Exception as e:
            logger.error(f"  [ÁîªÂÉè] JSONËß£ÊûêÂ§±Ë¥•ÔºåËæìÂá∫ÈïøÂ∫¶: {len(raw_output)}ÔºåÂâç500Â≠ó: {raw_output[:500]}")
            raise
        if not isinstance(profile, dict):
            profile = {}
        # Ë∞ÉËØïÔºöÊâìÂç∞Ëß£ÊûêÂêéÁöÑ job_profile ÂÖ≥ÈîÆÂ≠óÊÆµÔºàËß£ÊûêÂêé„ÄÅËΩ¨Êç¢ÂâçÁöÑÂéüÂßãÁªìÊûÑÔºâ
        req = profile.get("requirements") or {}
        core_skills = req.get("core_skills") or {}
        career = profile.get("career_development") or {}
        print("=== Ëß£ÊûêÂêé profile ÂÖ≥ÈîÆÂ≠óÊÆµ ===")
        print("technical_skills:", core_skills.get("technical_skills"))
        print("soft_skills:", core_skills.get("soft_skills"))
        print("advantages:", career.get("advantages"))
        print("core_skills(Êñ∞Ê†ºÂºè):", profile.get("core_skills"))
        print("reality_check(Êñ∞Ê†ºÂºè):", profile.get("reality_check"))
        print("ai_summary/description:", profile.get("ai_summary") or profile.get("description"))
        print("================================")
        # Ëã•Ê®°ÂûãËøîÂõûÊóßÁâàÁªìÊûÑÔºàbasic_info/requirementsÔºâÔºåËΩ¨‰∏∫Êñ∞ÁªìÊûÑÔºàcore_skills/reality_check/entry_path/ai_summaryÔºâ
        profile = _old_profile_to_new(profile)
        # ËßÑËåÉÂåñÁªìÊûÑÔºåÁ°Æ‰øùÂâçÁ´ØÊâÄÈúÄÂ≠óÊÆµÂ≠òÂú®ÔºàÈÅøÂÖçÂÖ®Á©∫Â±ïÁ§∫Ôºâ
        profile = _normalize_job_profile(profile)
        has_core = bool(profile.get("core_skills", {}).get("professional") or profile.get("core_skills", {}).get("tools"))
        has_reality = bool(profile.get("reality_check", {}).get("pros") or profile.get("reality_check", {}).get("cons"))
        has_summary = bool(profile.get("ai_summary") and str(profile.get("ai_summary")).strip())
        if not (has_core or has_reality or has_summary):
            logger.warning(f"  [ÁîªÂÉè] Ê®°ÂûãËøîÂõûÂÜÖÂÆπËæÉÂ∞ëÔºåÊ†∏ÂøÉÊäÄËÉΩ/ËÅåÂú∫Ê¥ûÂØü/ÊëòË¶ÅÂ§ö‰∏∫Á©∫ÔºåËØ∑Ê£ÄÊü•Ê®°ÂûãËæìÂá∫ÈïøÂ∫¶Êàñ prompt„ÄÇËæìÂá∫ÈïøÂ∫¶: {len(raw_output)}")

        # Step 5: Ê≥®ÂÖ•/Ê†°È™åÂÖ≥ÈîÆÂÖÉÊï∞ÊçÆ
        profile.setdefault("job_id",   job_id)
        profile.setdefault("job_name", job_name)
        profile.setdefault("category", category)
        profile["data_source"]      = data_source_label
        profile["csv_sample_count"] = len(matched_rows)
        profile["csv_market_meta"]  = market_meta
        profile["created_at"]       = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        profile["updated_at"]       = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        profile["status"]           = "completed"
        profile["_ai_confidence"]    = 0.88  # ‰æõ4.5Êé•Âè£ ai_confidence Â≠óÊÆµ‰ΩøÁî®
        profile["dimension_weights"] = weights

        logger.info(f"  ‚úÖ ÁîªÂÉèÁîüÊàêÂÆåÊàê: {job_name} | Êù•Ê∫ê: {data_source_label}")
        return profile

    # ===================================================
    # ÊâπÈáèÁîüÊàê
    # ===================================================
    def generate_all_profiles(self, force_regenerate: bool = False) -> dict:
        target_jobs = job_profile_conf.get("target_jobs", [])
        results, errors = {}, {}

        for i, job_config in enumerate(target_jobs, 1):
            job_id   = job_config["job_id"]
            job_name = job_config["name"]
            logger.info(f"[ÊâπÈáèÁîüÊàê] ({i}/{len(target_jobs)}) {job_name}")

            if not force_regenerate and job_id in self.profiles_store:
                logger.info(f"  Ë∑≥ËøáÔºàÂ∑≤ÊúâÁºìÂ≠òÔºâ")
                results[job_id] = self.profiles_store[job_id]
                continue

            try:
                profile = self.generate_profile(job_config)
                self.profiles_store[job_id] = profile
                results[job_id] = profile
                _save_profiles_store(self.profiles_store)
            except Exception as e:
                logger.error(f"  Â§±Ë¥•: {e}", exc_info=True)
                errors[job_id] = str(e)

        return {
            "results": results, "errors": errors,
            "total": len(target_jobs),
            "success_count": len(results), "error_count": len(errors),
        }

    def generate_by_category(self, category: str, force_regenerate: bool = False) -> dict:
        target_jobs = [j for j in job_profile_conf.get("target_jobs", [])
                       if j.get("category") == category]
        results, errors = {}, {}
        for job_config in target_jobs:
            job_id = job_config["job_id"]
            if not force_regenerate and job_id in self.profiles_store:
                results[job_id] = self.profiles_store[job_id]
                continue
            try:
                profile = self.generate_profile(job_config)
                self.profiles_store[job_id] = profile
                results[job_id] = profile
                _save_profiles_store(self.profiles_store)
            except Exception as e:
                errors[job_id] = str(e)
        return {"results": results, "errors": errors,
                "success_count": len(results), "error_count": len(errors)}

    # ===================================================
    # Êü•ËØ¢Êé•Âè£
    # ===================================================
    def get_profile_list(self, page=1, size=20, keyword=None,
                         industry=None, level=None, category=None) -> dict:
        # ‰ªéÂÖ®ÈáèÊï∞ÊçÆÂºÄÂßãÔºå‰ªÖÂú®ÊúâÊúâÊïàÁ≠õÈÄâÊù°‰ª∂Êó∂ÊâçËøáÊª§ÔºàÁ©∫ keyword/ÂÖ®ÈÉ®Ë°å‰∏ö/ÂÖ®ÈÉ®Á∫ßÂà´ ‰∏çËøáÊª§Ôºâ
        profiles = list(self.profiles_store.values())
        total_count_before_filter = len(profiles)  # Ë∞ÉËØïÁî®ÔºöËøáÊª§ÂâçÊÄªÊï∞ÊçÆÈáè

        # „ÄêÈóÆÈ¢ò1„Äë‰ªÖÂΩì keyword ÈùûÁ©∫Êó∂ÊâçÊåâËÅå‰ΩçÂêçÁß∞ËøáÊª§ÔºåÈÅøÂÖçÁ©∫Â≠óÁ¨¶‰∏≤ÂΩìÊù°‰ª∂ÂØºËá¥ÁªìÊûú‰∏∫Á©∫ÊàñÂºÇÂ∏∏
        kw = (keyword or "").strip()
        if kw:
            profiles = [p for p in profiles
                        if kw.lower() in ((p.get("job_name") or "").lower())]
            def _relevance(p):
                name = (p.get("job_name") or "").lower()
                k = kw.lower()
                if name == k:
                    return 0
                if name.startswith(k):
                    return 1
                return 2
            profiles.sort(key=_relevance)

        # Ë°å‰∏öÔºö‰ªÖÂΩì‰º†ÂÖ•ÊúâÊïàÂÄº‰∏îÈùû„ÄåÂÖ®ÈÉ®„ÄçÊó∂ÊâçËøáÊª§
        if industry and industry not in ("", "ÂÖ®ÈÉ®Ë°å‰∏ö", "ÂÖ®ÈÉ®"):
            profiles = [p for p in profiles
                        if industry in (p.get("basic_info") or {}).get("industry", "")]
        # Á∫ßÂà´Ôºö‰ªÖÂΩì‰º†ÂÖ•ÊúâÊïàÂÄº‰∏îÈùû„ÄåÂÖ®ÈÉ®„ÄçÊó∂ÊâçËøáÊª§
        if level and level not in ("", "ÂÖ®ÈÉ®Á∫ßÂà´", "ÂÖ®ÈÉ®"):
            def _level_match(p):
                lr = (p.get("basic_info") or {}).get("level_range") or []
                if not isinstance(lr, list):
                    lr = [lr] if lr else []
                return level in lr
            profiles = [p for p in profiles if _level_match(p)]
        if category:
            profiles = [p for p in profiles if p.get("category") == category]

        # ÊåâÂ≤ó‰ΩçÂêçÁß∞Áõ∏‰ººÂ∫¶ÂéªÈáçÔºå‰øùÁïôÊØèÁ±ªÂ≤ó‰ΩçÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑ‰∏ÄÊù°ÔºàÂéªÈáçÂêéÂÜçÂàÜÈ°µÔºâ
        seen_names = set()
        deduped = []
        for p in profiles:
            core_name = re.sub(r"[Ôºà(].*?[)Ôºâ]", "", p.get("job_name", "") or "").strip()
            core_name = re.sub(r"[¬∑‚Ä¢\-¬∑].*", "", core_name).strip()
            if core_name not in seen_names:
                seen_names.add(core_name)
                deduped.append(p)
        profiles = deduped

        total = len(profiles)
        # Ë∞ÉËØïÊó•ÂøóÔºöÊÄªÊï∞ÊçÆÈáè / ËøáÊª§ÂêéÊù°Êï∞ / keyword
        print(f"ÊÄªÊï∞ÊçÆÈáè: {total_count_before_filter}, ËøáÊª§Âêé: {len(profiles)}, keyword='{keyword or ''}'")
        # „ÄêÈóÆÈ¢ò2„ÄëÂàÜÈ°µÔºöstart = (page-1)*size, end = start+sizeÔºåÂèñ records[start:end]
        start = (page - 1) * size
        end = start + size
        page_data = profiles[start:end]

        def _item(p):
            bi = p.get("basic_info", {})
            ma = p.get("market_analysis", {})
            skills = []
            req = p.get("requirements", {}) or {}
            ps = req.get("professional_skills") or {}
            if ps.get("programming_languages"):
                skills.extend([x.get("skill") for x in ps["programming_languages"] if x.get("skill")])
            if ps.get("frameworks_tools"):
                skills.extend([x.get("skill") for x in ps["frameworks_tools"] if x.get("skill")])
            if not skills and ma.get("tags"):
                skills = ma.get("tags", [])[:6]
            # salary_rangeÔºöCSV ‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÊóßÁîªÂÉè‰∏∫ dictÔºåÂÖºÂÆπ‰∏§Áßç
            sr = bi.get("salary_range")
            avg_salary = sr.get("junior", "") if isinstance(sr, dict) else (sr or "")
            # level_rangeÔºöÂèØËÉΩÊòØ list ÊàñÂçïÂÄº
            lr = bi.get("level_range") or []
            if not isinstance(lr, list):
                lr = [lr] if lr else [""]
            level_str = lr[0] if lr else ""
            # industry / location / company_scaleÔºöCSV ‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÂÖºÂÆπÊóßÊï∞ÊçÆ
            ind = bi.get("industry")
            industry_str = ind if isinstance(ind, str) else (ind.get("name", "") if isinstance(ind, dict) else "")
            return {
                "job_id":       p.get("job_id"),
                "job_name":     p.get("job_name"),
                "job_code":     p.get("job_code"),
                "category":     p.get("category"),
                "industry":     industry_str,
                "level_range":  lr,
                "level":        level_str,
                "avg_salary":   avg_salary,
                "description":  bi.get("description"),
                "demand_score": ma.get("demand_score", 0),
                "growth_trend": ma.get("growth_trend"),
                "tags":         ma.get("tags", []),
                "skills":       skills,
                "data_source":  p.get("data_source"),
                "created_at":   p.get("created_at"),
            }
        return {
            "total": total, "page": page, "size": size,
            "list": [_item(p) for p in page_data],
        }

    def get_industries(self) -> list:
        """ËøîÂõûÊâÄÊúâÂ≤ó‰Ωç‰∏≠ÁöÑÂéªÈáçË°å‰∏öÂàóË°®ÔºåÁî®‰∫éÂâçÁ´ØÁ≠õÈÄâ‰∏ãÊãâ"""
        industries = set()
        for p in self.profiles_store.values():
            ind = (p.get("basic_info") or {}).get("industry")
            if ind:
                industries.add(ind.strip())
        return sorted(industries)

    def get_profile_detail(self, job_id: str) -> Optional[dict]:
        p = self.profiles_store.get(job_id)
        return _normalize_profile(p) if p else None

    def get_profile_by_name(self, job_name: str) -> Optional[dict]:
        for p in self.profiles_store.values():
            if p.get("job_name") == job_name:
                return _normalize_profile(p)
        for p in self.profiles_store.values():
            if job_name in p.get("job_name", ""):
                return _normalize_profile(p)
        return None

    def get_category_summary(self) -> dict:
        target_jobs = job_profile_conf.get("target_jobs", [])
        summary = {}
        for job_config in target_jobs:
            cat = job_config.get("category", "Êú™ÂàÜÁ±ª")
            if cat not in summary:
                summary[cat] = {"total": 0, "generated": 0, "jobs": []}
            summary[cat]["total"] += 1
            done = job_config["job_id"] in self.profiles_store
            if done:
                summary[cat]["generated"] += 1
            profile = self.profiles_store.get(job_config["job_id"], {})
            summary[cat]["jobs"].append({
                "job_id":      job_config["job_id"],
                "name":        job_config["name"],
                "done":        done,
                "data_source": profile.get("data_source", "‚Äî"),
                "csv_samples": profile.get("csv_sample_count", 0),
            })
        return summary

    def preview_csv_match(self) -> dict:
        """È¢ÑËßàÂêÑÂ≤ó‰ΩçËÉΩ‰ªéCSV‰∏≠ÂåπÈÖçÂà∞Â§öÂ∞ëÊù°Êï∞ÊçÆÔºà‰∏çÁîüÊàêÁîªÂÉèÔºåÂè™ÁªüËÆ°Ôºâ"""
        result = {}
        for job_config in job_profile_conf.get("target_jobs", []):
            keywords = job_config.get("csv_keywords", [job_config["name"]])
            matched  = self.extractor.search(keywords, max_count=20)
            result[job_config["job_id"]] = {
                "name":    job_config["name"],
                "matched": len(matched),
                "samples": [r.get("ËÅå‰ΩçÂêçÁß∞", "") for r in matched],
                "strategy": "Êï∞ÊçÆÈõÜJDÂàÜÊûê" if matched else "Ê®°ÂûãÁîüÊàê",
            }
        return result

    def reload_store(self):
        self.profiles_store = _load_profiles_store()


# ========== Âçï‰æã ==========
_instance: Optional[JobProfileService] = None


def get_job_profile_service() -> JobProfileService:
    global _instance
    if _instance is None:
        _instance = JobProfileService()
    return _instance


# ========== CLI ==========
if __name__ == "__main__":
    import sys
    service = JobProfileService()
    cmd = sys.argv[1] if len(sys.argv) > 1 else "--preview"

    if cmd == "--preview":
        print("=== CSVÂåπÈÖçÈ¢ÑËßàÔºà‰∫ÜËß£Âì™‰∫õÂ≤ó‰ΩçÊúâÁúüÂÆûÊï∞ÊçÆÔºâ===\n")
        preview = service.preview_csv_match()
        for jid, info in preview.items():
            mark = "üìä" if info["matched"] > 0 else "ü§ñ"
            print(f"{mark} {jid} {info['name']:20s} | ÂåπÈÖç{info['matched']:2d}Êù° | {info['strategy']}")
            if info["samples"]:
                print(f"     ÂåπÈÖçÂà∞: {', '.join(info['samples'][:3])}")

    elif cmd == "--status":
        summary = service.get_category_summary()
        for cat, info in summary.items():
            print(f"\n„Äê{cat}„Äë({info['generated']}/{info['total']})")
            for j in info["jobs"]:
                mark = "‚úÖ" if j["done"] else "‚è≥"
                src  = f"[{j['data_source']}]" if j["done"] else ""
                print(f"  {mark} {j['name']} {src}")

    elif cmd == "--generate":
        job_name = sys.argv[2] if len(sys.argv) > 2 else None
        target_jobs = job_profile_conf.get("target_jobs", [])
        cfg = next((j for j in target_jobs if j["name"] == job_name), None)
        if cfg:
            profile = service.generate_profile(cfg)
            service.profiles_store[cfg["job_id"]] = profile
            _save_profiles_store(service.profiles_store)
            print(f"Êù•Ê∫ê: {profile['data_source']}")
            print(f"CSVÊ†∑Êú¨Êï∞: {profile['csv_sample_count']}")
            print(json.dumps(profile, ensure_ascii=False, indent=2)[:2000])
        else:
            print(f"Êú™ÊâæÂà∞: {job_name}")
