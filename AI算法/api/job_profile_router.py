"""
å²—ä½ç”»åƒæ¨¡å— API è·¯ç”±
å¯¹åº” API æ–‡æ¡£ç¬¬ 4 ç« ï¼šJob Profile æ¨¡å—

è·¯ç”±åˆ—è¡¨ï¼š
  POST /api/v1/job/profiles             - 4.1 è·å–å²—ä½ç”»åƒåˆ—è¡¨
  POST /api/v1/job/profile/detail       - 4.2 è·å–å²—ä½è¯¦ç»†ç”»åƒ
  POST /api/v1/job/relation-graph       - 4.3 è·å–å²—ä½å…³è”å›¾è°±
  POST /api/v1/job/ai-generate-profile  - 4.4 AIç”Ÿæˆå²—ä½ç”»åƒ
  POST /api/v1/job/ai-generate-result   - 4.5 è·å–AIç”Ÿæˆç»“æœ
"""

import csv
import json
import os
from flask import Blueprint, request, jsonify
from datetime import datetime
import threading

import csv
from job_profile.job_profile_service import get_job_profile_service, job_profile_conf, _load_profiles_store
from job_profile.job_graph_service import get_job_graph_service
from job_profile.career_path_generator import generate_career_path
from utils.logger_handler import logger
from utils.path_tool import get_abs_path

# åˆ›å»ºBlueprint
job_bp = Blueprint("job", __name__, url_prefix="/api/v1/job")


# ========== ç»Ÿä¸€å“åº”æ ¼å¼ï¼ˆå¯¹åº”APIæ–‡æ¡£ 0.3ï¼‰==========

def success_response(data, msg="success"):
    return jsonify({"code": 200, "msg": msg, "data": data})


def error_response(code, msg, data=None):
    return jsonify({"code": code, "msg": msg, "data": data}), code


# ========== å¼‚æ­¥ä»»åŠ¡ç®¡ç†ï¼ˆç”¨äºé•¿è€—æ—¶çš„AIç”Ÿæˆä»»åŠ¡ï¼‰==========

_tasks = {}  # task_id -> {status, result, error}
_tasks_lock = threading.Lock()
_TASKS_STORE_DIR = None  # å»¶è¿Ÿè®¡ç®—ï¼Œé¿å…å¾ªç¯ä¾èµ–


def _get_tasks_store_path():
    global _TASKS_STORE_DIR
    if _TASKS_STORE_DIR is None:
        _TASKS_STORE_DIR = get_abs_path("data/ai_tasks")
        os.makedirs(_TASKS_STORE_DIR, exist_ok=True)
    return os.path.join(_TASKS_STORE_DIR, "state.json")


def _persist_tasks():
    """å°†å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€å†™å…¥æ–‡ä»¶ï¼Œä¾¿äºå¤šè¿›ç¨‹/é‡å¯åä»èƒ½æŸ¥åˆ°ç»“æœ"""
    try:
        path = _get_tasks_store_path()
        with _tasks_lock:
            snapshot = {}
            for tid, t in _tasks.items():
                snapshot[tid] = {
                    "status": t.get("status", "pending"),
                    "result": t.get("result"),
                    "error": t.get("error"),
                }
        raw = json.dumps(snapshot, ensure_ascii=False, default=str)
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            f.write(raw)
        if os.path.exists(path):
            os.remove(path)
        os.rename(tmp, path)
    except Exception as e:
        logger.warning(f"[AsyncTask] æŒä¹…åŒ–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")


def _load_persisted_tasks():
    """ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡çŠ¶æ€ï¼Œåˆå¹¶åˆ° _tasksï¼ˆä¸è¦†ç›–å·²æœ‰ keyï¼‰"""
    try:
        path = _get_tasks_store_path()
        if not os.path.exists(path):
            return
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        with _tasks_lock:
            for tid, t in data.items():
                if tid not in _tasks:
                    _tasks[tid] = {
                        "status": t.get("status", "pending"),
                        "result": t.get("result"),
                        "error": t.get("error"),
                    }
    except Exception as e:
        logger.warning(f"[AsyncTask] åŠ è½½æŒä¹…åŒ–ä»»åŠ¡å¤±è´¥: {e}")


def _run_task_async(task_id: str, func, *args, **kwargs):
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œä»»åŠ¡ï¼ŒçŠ¶æ€ä¼šæŒä¹…åŒ–åˆ°æ–‡ä»¶ï¼Œé¿å…å¤šè¿›ç¨‹/é‡å¯å 404"""
    def run():
        try:
            _tasks[task_id]["status"] = "processing"
            _persist_tasks()
            result = func(*args, **kwargs)
            _tasks[task_id]["status"] = "completed"
            _tasks[task_id]["result"] = result
            _persist_tasks()
        except Exception as e:
            logger.error(f"[AsyncTask] ä»»åŠ¡{task_id}å¤±è´¥: {e}", exc_info=True)
            _tasks[task_id]["status"] = "failed"
            _tasks[task_id]["error"] = str(e)
            _persist_tasks()

    _tasks[task_id] = {"status": "pending", "result": None, "error": None}
    _persist_tasks()
    thread = threading.Thread(target=run, daemon=True)
    thread.start()


# ============================================================
# 4.1 è·å–å²—ä½ç”»åƒåˆ—è¡¨
# POST /api/v1/job/profiles  æˆ–  GET /api/v1/job/profiles?page=1&size=12&keyword=xxx&industry=xxx&level=xxx
# ============================================================
def _get_profiles_params():
    """ä» GET æŸ¥è¯¢ä¸²æˆ– POST body è¯»å– page, size, keyword, industry, level"""
    if request.method == "GET":
        page = request.args.get("page", "1")
        size = request.args.get("size", "20")
        keyword = request.args.get("keyword", "").strip() or None
        industry = request.args.get("industry", "").strip() or None
        level = request.args.get("level", "").strip() or None
    else:
        body = request.get_json(silent=True) or {}
        page = body.get("page", 1)
        size = body.get("size", 20)
        keyword = body.get("keyword") or None
        industry = body.get("industry") or None
        level = body.get("level") or None
    page = int(page) if page else 1
    size = int(size) if size else 20
    return page, size, keyword, industry, level


@job_bp.route("/profiles", methods=["GET", "POST"])
def get_job_profiles():
    """
    è·å–å²—ä½ç”»åƒåˆ—è¡¨ã€‚GET ç”¨æŸ¥è¯¢å‚æ•°ï¼ŒPOST ç”¨è¯·æ±‚ä½“ã€‚
    å‚æ•°ï¼špage, size, keyword, industry, level
    """
    try:
        page, size, keyword, industry, level = _get_profiles_params()
        if page < 1 or size < 1 or size > 100:
            return error_response(400, "åˆ†é¡µå‚æ•°é”™è¯¯ï¼špage>=1, 1<=size<=100")

        service = get_job_profile_service()
        result = service.get_profile_list(page=page, size=size,
                                          keyword=keyword, industry=industry, level=level)
        return success_response(result)

    except Exception as e:
        logger.error(f"[API] /job/profiles å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# çœŸå®æ‹›è˜æ•°æ®ï¼šå…ˆæŸ¥ CSVï¼ˆå‰4å­—æ¨¡ç³ŠåŒ¹é…ï¼‰ï¼Œæ— ç»“æœåˆ™ AI ç”Ÿæˆï¼Œè¿”å›ä¸åŠ  isAIGenerated
# GET /api/v1/job/real-data?jobName=ç®—æ³•å·¥ç¨‹å¸ˆ&size=5
# ============================================================

def _search_csv(job_name, size):
    """ä» CSV æŒ‰å²—ä½åå‰ 4 å­—æ¨¡ç³ŠåŒ¹é…ï¼Œæœ€å¤šè¿”å› size æ¡ã€‚"""
    csv_path = get_abs_path("data/æ±‚èŒå²—ä½ä¿¡æ¯æ•°æ®.csv")
    if not job_name or not os.path.exists(csv_path):
        return []
    keyword = (job_name[:4] if len(job_name) >= 4 else job_name).strip()
    if not keyword:
        return []
    results = []
    try:
        with open(csv_path, encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                title = (row.get("èŒä½åç§°") or "").strip()
                if keyword in title:
                    desc = (row.get("èŒä½æè¿°") or "").strip()
                    intro = (row.get("å…¬å¸ç®€ä»‹") or "").strip()
                    results.append({
                        "jobTitle": title,
                        "company": row.get("å…¬å¸å…¨ç§°", ""),
                        "salary": row.get("è–ªèµ„èŒƒå›´", ""),
                        "address": row.get("å·¥ä½œåœ°å€", ""),
                        "industry": row.get("æ‰€å±è¡Œä¸š", ""),
                        "scale": row.get("äººå‘˜è§„æ¨¡", ""),
                        "companyType": row.get("ä¼ä¸šæ€§è´¨", ""),
                        "description": (desc[:200] + "â€¦") if len(desc) > 200 else desc,
                        "companyIntro": (intro[:150] + "â€¦") if len(intro) > 150 else intro,
                    })
                    if len(results) >= size:
                        break
    except Exception as e:
        logger.warning(f"[API] real-data è¯»å– CSV å¤±è´¥: {e}", exc_info=True)
    return results


@job_bp.route("/real-data", methods=["GET"])
def get_real_data():
    job_name = (request.args.get("jobName") or "").strip()
    try:
        size = int(request.args.get("size", 3))
        size = max(1, min(size, 20))
    except (TypeError, ValueError):
        size = 3

    results = _search_csv(job_name, size)

    if not results:
        try:
            from dashscope import Generation
            prompt = f"""ä¸ºå²—ä½ã€{job_name}ã€‘ç”Ÿæˆ{size}æ¡æ‹›è˜ä¿¡æ¯ï¼Œé£æ ¼çœŸå®è‡ªç„¶ã€‚
åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š
{{"jobs":[
  {{
    "jobTitle":"{job_name}",
    "company":"å…¬å¸å",
    "salary":"è–ªèµ„èŒƒå›´",
    "address":"åŸå¸‚Â·åŒºÂ·è¡—é“",
    "industry":"è¡Œä¸š",
    "scale":"äººå‘˜è§„æ¨¡",
    "companyType":"ä¼ä¸šæ€§è´¨",
    "description":"èŒä½æè¿°120å­—",
    "companyIntro":"å…¬å¸ç®€ä»‹60å­—"
  }}
]}}
è¯·æŒ‰ä¸Šè¿°æ ¼å¼ç”Ÿæˆ{size}æ¡ï¼Œæ¯æ¡å­—æ®µå®Œæ•´ã€‚"""
            response = Generation.call(
                model="qwen3-max",
                messages=[{"role": "user", "content": prompt}],
                result_format="message",
            )
            content = (response.output.choices[0].message.content or "").strip()
            content = content.replace("```json", "").replace("```", "").strip()
            data = json.loads(content)
            results = data.get("jobs", [])[:size]
        except Exception as e:
            logger.error(f"[API] real-data AI ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            results = []

    return success_response(results)


# ============================================================
# è·å–è¡Œä¸šåˆ—è¡¨ï¼ˆä¾›å‰ç«¯ç­›é€‰ä¸‹æ‹‰åŠ¨æ€åŠ è½½ï¼‰
# GET /api/v1/job/industries
# ============================================================
@job_bp.route("/industries", methods=["GET"])
def get_job_industries():
    """è¿”å›æ‰€æœ‰å²—ä½ä¸­çš„å»é‡è¡Œä¸šåˆ—è¡¨"""
    try:
        service = get_job_profile_service()
        industries = service.get_industries()
        return success_response({"industries": industries})
    except Exception as e:
        logger.error(f"[API] /job/industries å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.2 è·å–å²—ä½è¯¦ç»†ç”»åƒ
# POST /api/v1/job/profile/detail
# ============================================================
def _minimal_profile_from_target_jobs(job_id_or_name):
    """å½“ store ä¸­æ— è¯¥å²—ä½æ—¶ï¼Œç”¨ target_jobs é…ç½®å…œåº•ï¼Œé¿å…ã€Œå²—ä½ç”»åƒã€æŒ‰é’® 404ã€‚ä¸çœŸå®æ•°æ®æ¥å£äº’ç‹¬ç«‹ã€‚"""
    target = job_profile_conf.get("target_jobs", [])
    job_id_or_name = (job_id_or_name or "").strip()
    if not job_id_or_name:
        return None
    for j in target:
        if j.get("job_id") == job_id_or_name or (j.get("name") or "").strip() == job_id_or_name:
            name = j.get("name", "")
            level_map = {1: "å®ä¹ /åŠ©ç†", 2: "åˆçº§", 3: "ä¸­çº§", 4: "é«˜çº§", 5: "æ¶æ„å¸ˆ", 6: "æ€»ç›‘"}
            level = level_map.get(j.get("layer_level"), "ä¸­çº§")
            return {
                "job_id": j.get("job_id", ""),
                "job_name": name,
                "basic_info": {
                    "industry": j.get("category", "äº’è”ç½‘/AI"),
                    "level": level,
                    "level_range": [level],
                    "avg_salary": "é¢è®®",
                    "work_locations": [],
                    "company_scales": [],
                    "description": f"è¯¥å²—ä½æš‚æ— è¯¦ç»†ç”»åƒï¼Œå¯åœ¨ã€ŒAIç”Ÿæˆã€é¡µè¾“å…¥ã€Œ{name}ã€ç”Ÿæˆå®Œæ•´ç”»åƒã€‚",
                },
                "market_analysis": {"demand_score": 80, "growth_trend": "ä¸Šå‡"},
                "description": f"æ¥è‡ªå²—ä½é…ç½®ï¼š{name}ï¼ˆ{j.get('category', '')}ï¼‰ã€‚ç‚¹å‡» AI ç”Ÿæˆå¯è·å–å®Œæ•´ç”»åƒã€‚",
            }
    for j in target:
        if job_id_or_name in (j.get("name") or ""):
            return _minimal_profile_from_target_jobs(j.get("name"))
    return None


@job_bp.route("/profile/detail", methods=["POST"])
def get_job_profile_detail():
    """
    è·å–å•ä¸ªå²—ä½çš„å®Œæ•´è¯¦ç»†ç”»åƒ
    è¯·æ±‚ä½“ï¼š{ job_id } æˆ– { job_name }
    """
    try:
        body = request.get_json(silent=True) or {}
        job_id = body.get("job_id")
        job_name = body.get("job_name")

        if not job_id and not job_name:
            return error_response(400, "è¯·æä¾› job_id æˆ– job_name å‚æ•°")

        service = get_job_profile_service()
        profile = None

        if job_id:
            profile = service.get_profile_detail(job_id)
        if not profile and job_name:
            profile = service.get_profile_by_name(job_name)
        if not profile and job_id:
            profile = service.get_profile_by_name(job_id)

        # è‹¥ä»æ— ç”»åƒï¼ˆå¦‚åˆ—è¡¨æ¥è‡ªç²¾é€‰é…ç½® job_001 ä½† store æ¥è‡ª CSVï¼‰ï¼Œç”¨ target_jobs å…œåº•ï¼Œé¿å… 404
        if not profile:
            profile = _minimal_profile_from_target_jobs(job_id or job_name)

        if not profile:
            return error_response(404, f"æœªæ‰¾åˆ°å²—ä½ç”»åƒï¼š{job_id or job_name}")

        return success_response(profile)

    except Exception as e:
        logger.error(f"[API] /job/profile/detail å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.3 è·å–å²—ä½å…³è”å›¾è°±
# POST /api/v1/job/relation-graph
# ============================================================
def _empty_graph_data(center_job_id=None, message="æš‚æ— æ•°æ®"):
    """è¿”å›å‰ç«¯æœŸæœ›çš„ç©ºå›¾è°±ç»“æ„ï¼Œé¿å…ç©ºå“åº”æˆ–ç¼ºå¤±å­—æ®µå¯¼è‡´åŠ è½½å¤±è´¥"""
    return {
        "center_job": {"job_id": center_job_id or "", "job_name": "", "level": 0, "salary_range": "", "avg_salary": "", "demand_score": None},
        "vertical_graph": {"nodes": [], "edges": [], "track_name": "", "message": message},
        "transfer_graph": {"nodes": [], "edges": [], "message": message},
        "career_path": {"promotion_path": []},
    }


def _resolve_job_id_from_name(job_name):
    """æ ¹æ®å²—ä½åç§°è§£æä¸º target_jobs çš„ job_idï¼Œç”¨äºæ™‹å‡è·¯å¾„æŸ¥åº“ã€‚"""
    job_name = (job_name or "").strip()
    if not job_name:
        return None
    import re
    name_core = re.sub(r"\s*[ï¼ˆ(].*?[)ï¼‰]\s*", "", job_name).strip() or job_name
    target_jobs = job_profile_conf.get("target_jobs", [])
    for t in target_jobs:
        tid = t.get("job_id", "")
        tname = (t.get("name") or "").strip()
        if not tname:
            continue
        if name_core in tname or tname in name_core:
            return tid
    return None


def _resolve_job_id_for_graph(job_id):
    """
    å°†åˆ—è¡¨/CSV çš„ job_idï¼ˆå¦‚ A174435ï¼‰è§£æä¸ºå›¾è°±ä½¿ç”¨çš„ target_jobs job_idï¼ˆå¦‚ job_011ï¼‰ï¼Œ
    ä»¥ä¾¿ä» DB æˆ– graph.json ç§’çº§è¿”å›ï¼Œé¿å…èµ°å®æ—¶ LLM å¯¼è‡´è¯·æ±‚æŒ‚èµ·ã€å“åº”ä¸ºç©ºã€‚
    è¿”å› (resolved_id, display_name)ï¼šresolved_id ç”¨äºæŸ¥ DB/å›¾ï¼Œdisplay_name ç”¨äº center_job å±•ç¤ºã€‚
    """
    job_id = (job_id or "").strip()
    if not job_id:
        return None, ""
    target_jobs = job_profile_conf.get("target_jobs", [])
    job_index = {j["job_id"]: j for j in target_jobs}
    if job_id in job_index:
        return job_id, (job_index[job_id].get("name") or job_id)

    # ä» profiles_store å–å²—ä½åç§°ï¼Œå†æŒ‰åç§°åŒ¹é… target_jobs
    profiles = _load_profiles_store()
    job_name = ""
    if job_id in profiles:
        job_name = (profiles[job_id].get("job_name") or "").strip()
    if not job_name:
        job_name = job_id
    # å»æ‰æ‹¬å·åç¼€ä¾¿äºåŒ¹é…ï¼Œå¦‚ "ç®—æ³•å·¥ç¨‹å¸ˆ(A174435)" -> "ç®—æ³•å·¥ç¨‹å¸ˆ"
    import re
    name_core = re.sub(r"\s*[ï¼ˆ(].*?[)ï¼‰]\s*", "", job_name).strip() or job_name
    for t in target_jobs:
        tid = t.get("job_id", "")
        tname = (t.get("name") or "").strip()
        if not tname:
            continue
        if name_core in tname or tname in name_core:
            return tid, job_name or tname
    return job_id, job_name or job_id


def _build_graph_data_from_json(resolved_id, graph_type, display_name, job_index):
    """ä» data/job_profiles/graph.json æ„å»º API æ‰€éœ€ç»“æ„ï¼Œç§’çº§è¿”å›ï¼Œé¿å…è¯·æ±‚æŒ‚èµ·ã€‚"""
    graph_path = get_abs_path(job_profile_conf.get("job_graph_store", "data/job_profiles/graph.json"))
    if not graph_path or not os.path.isfile(graph_path):
        return None
    try:
        with open(graph_path, "r", encoding="utf-8") as f:
            graph_file = json.load(f)
    except Exception as e:
        logger.warning(f"[API] è¯»å– graph.json å¤±è´¥: {e}")
        return None
    nodes_by_id = {n["job_id"]: n for n in graph_file.get("transfer_graph", {}).get("nodes", [])}
    all_edges = graph_file.get("transfer_graph", {}).get("edges", [])
    center_node = nodes_by_id.get(resolved_id, {})
    center_name = display_name or center_node.get("job_name", resolved_id)
    center_job = {
        "job_id": resolved_id,
        "job_name": center_name,
        "level": center_node.get("layer_level", job_index.get(resolved_id, {}).get("layer_level", 0)),
        "salary_range": "",
        "avg_salary": "",
        "demand_score": None,
    }
    result = {"center_job": center_job}

    # å‚ç›´å›¾è°±ï¼šä» vertical_graphs ä¸­æ‰¾åˆ°åŒ…å« resolved_id çš„ track
    vertical_graphs = graph_file.get("vertical_graphs", [])
    v_nodes, v_edges, track_name = [], [], ""
    for track in vertical_graphs:
        nodes_list = track.get("nodes", [])
        ids_in_track = [n["job_id"] for n in nodes_list]
        if resolved_id in ids_in_track and graph_type in ("vertical", "all"):
            v_nodes = [{"job_id": n["job_id"], "job_name": n.get("job_name", n["job_id"]), "level": n.get("layer_level", 0), "category": n.get("category", ""), "salary_range": "", "description": ""} for n in nodes_list]
            v_edges = [{"from": e.get("from"), "to": e.get("to"), "years": e.get("years", "2-3å¹´"), "requirements": e.get("requirements", [])} for e in track.get("edges", [])]
            track_name = track.get("career_track", "æ™‹å‡è·¯å¾„")
            break
    result["vertical_graph"] = {"nodes": v_nodes, "edges": v_edges, "track_name": track_name, "message": "" if v_nodes else "æš‚æ— å‚ç›´è·¯å¾„"}

    # è½¬å²—å›¾è°±ï¼šedges ä¸­ from == resolved_id çš„è¾¹åŠå…¶ to èŠ‚ç‚¹
    out_edges = [e for e in all_edges if e.get("from") == resolved_id]
    to_ids = list({e.get("to") for e in out_edges if e.get("to")})
    transfer_nodes = [nodes_by_id.get(jid, {"job_id": jid, "job_name": jid}) for jid in to_ids]
    transfer_nodes = [{"job_id": n["job_id"], "job_name": n.get("job_name", n["job_id"]), "level": n.get("layer_level", 0), "category": n.get("category", ""), "salary_range": "", "description": ""} for n in transfer_nodes]
    transfer_edges = [
        {"from": e["from"], "to": e["to"], "relevance_score": e.get("relevance_score", 70), "match_score": e.get("relevance_score", 70), "difficulty": e.get("difficulty", "ä¸­"), "time": e.get("time", "6-12ä¸ªæœˆ"), "skills_gap": e.get("skills_gap", [])}
        for e in out_edges[:15]
    ]
    result["transfer_graph"] = {"nodes": transfer_nodes, "edges": transfer_edges, "message": ""}
    result["career_path"] = {"promotion_path": []}
    return result


@job_bp.route("/relation-graph", methods=["POST"])
def get_job_relation_graph():
    """
    è·å–å²—ä½é—´çš„è¡€ç¼˜å…³ç³»å’Œè½¬æ¢è·¯å¾„
    è¯·æ±‚ä½“ï¼š{ job_id, graph_type }
    graph_type: vertical / transfer / all
    åˆ—è¡¨ job_idï¼ˆå¦‚ A174435ï¼‰ä¼šè§£æä¸º target_jobs idï¼ˆå¦‚ job_011ï¼‰ï¼Œä¼˜å…ˆ DB / graph.json ç§’çº§è¿”å›ï¼Œé¿å…å“åº”æŒ‚èµ·ä¸ºç©ºã€‚
    """
    body = request.get_json(silent=True) or {}
    job_id = (body.get("job_id") or "").strip()
    graph_type = body.get("graph_type", "all")
    logger.info(f"[API] relation-graph æ¥å£è¢«è°ƒç”¨, å‚æ•°: job_id={job_id!r}, graph_type={graph_type!r}")

    try:
        if not job_id:
            return error_response(400, "è¯·æä¾› job_id å‚æ•°")

        if graph_type not in ("vertical", "transfer", "all"):
            return error_response(400, "graph_type å‚æ•°é”™è¯¯ï¼Œæ”¯æŒ: vertical/transfer/all")

        resolved_id, display_name = _resolve_job_id_for_graph(job_id)
        if not resolved_id:
            return error_response(400, "æ— æ³•è§£æå²—ä½ ID")
        job_index = {j["job_id"]: j for j in job_profile_conf.get("target_jobs", [])}

        # 1) ä¼˜å…ˆä» job_relations è¡¨è¯»å–
        try:
            from job_profile.job_relations_db import init_db, build_graph_data_from_db
            init_db()
            db_data = build_graph_data_from_db(resolved_id, graph_type, job_index)
            if db_data is not None:
                for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                    if key not in db_data:
                        db_data[key] = _empty_graph_data(resolved_id)[key]
                if display_name and db_data.get("center_job"):
                    db_data["center_job"]["job_name"] = display_name
                return success_response(db_data)
        except Exception as e:
            logger.warning(f"[API] relation-graph ä» DB è¯»å–å¤±è´¥: {e}")

        # 2) ä» graph.json ç§’çº§è¿”å›ï¼Œé¿å…å®æ—¶ LLM å¯¼è‡´æŒ‚èµ·ã€å“åº”ä¸ºç©º
        json_data = _build_graph_data_from_json(resolved_id, graph_type, display_name, job_index)
        if json_data is not None:
            for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                if key not in json_data:
                    json_data[key] = _empty_graph_data(resolved_id)[key]
            return success_response(json_data)

        # 3) å›é€€å®æ—¶æ„å»ºï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
        graph_service = get_job_graph_service()
        graph_data = graph_service.get_job_graph(resolved_id, graph_type)

        if not isinstance(graph_data, dict):
            graph_data = _empty_graph_data(resolved_id, "æ•°æ®æ ¼å¼å¼‚å¸¸")
        else:
            for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                if key not in graph_data:
                    graph_data[key] = _empty_graph_data(resolved_id)[key]
        if display_name and graph_data.get("center_job"):
            graph_data["center_job"]["job_name"] = display_name
        return success_response(graph_data)

    except ValueError as e:
        logger.warning(f"[API] /job/relation-graph ä¸šåŠ¡é”™è¯¯: {e}")
        return error_response(404, str(e))
    except Exception as e:
        logger.error(f"[API] /job/relation-graph å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.3.1 è·å–å²—ä½æ™‹å‡è·¯å¾„ï¼ˆä¼˜å…ˆ DB job_promotion_pathï¼Œå¦åˆ™ LLM ç”Ÿæˆï¼‰
# GET /api/v1/job/career-path?jobName=xxxï¼ˆå‰ç«¯æ™‹å‡è·¯å¾„å¡ç‰‡å¯æ¥æ­¤ï¼›é˜Ÿå‹ä¾§ jobId æ¢å²—æ•°æ®å¯å¦æ¥ï¼‰
# ============================================================
@job_bp.route("/career-path", methods=["GET"])
def get_job_career_path():
    """
    æ ¹æ®å²—ä½åç§°æˆ– jobId è¿”å› 4 ä¸ªæ™‹å‡é˜¶æ®µï¼Œä¾›å‰ç«¯æ™‹å‡è·¯å¾„å¡ç‰‡ä½¿ç”¨ã€‚
    æ”¯æŒ jobName æˆ– jobIdï¼šjobId æ—¶ä» profiles_store è§£æå²—ä½åç§°ã€‚
    ä¼˜å…ˆä» job_promotion_path è¡¨è¯»å–ï¼Œç¡®ä¿æœ‰é˜¶æ®µåã€å¹´é™ã€è–ªèµ„ï¼›æ— åˆ™å›é€€ LLMã€‚
    è¿”å› data.path: [ { stage, icon, salary, skills, desc, years }, ... ]
    """
    try:
        job_name = (request.args.get("jobName") or "").strip()
        job_id = (request.args.get("jobId") or "").strip()
        if not job_name and job_id:
            profiles = _load_profiles_store()
            profile = profiles.get(job_id) if isinstance(profiles, dict) else None
            if profile and isinstance(profile, dict):
                job_name = (profile.get("job_name") or profile.get("name") or "").strip()
            if not job_name:
                resolved_id, display_name = _resolve_job_id_for_graph(job_id)
                if display_name:
                    job_name = display_name
        if not job_name:
            return error_response(400, "è¯·æä¾› jobName æˆ– jobId å‚æ•°")

        path = []
        job_id = _resolve_job_id_from_name(job_name)
        if job_id:
            try:
                from job_profile.job_relations_db import init_db, get_promotion_path_by_job_id
                init_db()
                rows = get_promotion_path_by_job_id(job_id)
                if rows and len(rows) >= 4:
                    default_icons = ["ğŸŒ±", "ğŸŒ¿", "ğŸŒ³", "ğŸ†"]
                    for i, r in enumerate(rows[:4]):
                        skills = r.get("skills")
                        if isinstance(skills, str) and skills.strip():
                            try:
                                skills = json.loads(skills)
                            except Exception:
                                skills = [s.strip() for s in skills.split(",") if s.strip()]
                        else:
                            skills = []
                        path.append({
                            "stage": r.get("stage_name") or r.get("role_title") or "",
                            "icon": (r.get("icon") or "").strip() or default_icons[i],
                            "salary": r.get("salary_range") or "",
                            "skills": skills if isinstance(skills, list) else [],
                            "desc": "",
                            "years": r.get("years_range") or "",
                        })
            except Exception as e:
                logger.warning(f"[API] career-path ä» DB è¯»å–å¤±è´¥ï¼Œå›é€€ LLM: {e}")

        if not path:
            raw = generate_career_path(job_name)
            for i, s in enumerate(raw[:4]):
                path.append({
                    "stage": s.get("name", ""),
                    "icon": s.get("icon", "ğŸŒ±"),
                    "salary": s.get("salary_increase", ""),
                    "skills": s.get("key_skills") or [],
                    "desc": s.get("desc", ""),
                    "years": s.get("time_range", ""),
                })

        return success_response({"path": path})
    except Exception as e:
        logger.error(f"[API] /job/career-path å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.4 AIç”Ÿæˆå²—ä½ç”»åƒï¼ˆå¼‚æ­¥è§¦å‘ï¼‰
# POST /api/v1/job/ai-generate-profile
# ============================================================

def _resolve_job_config(job_name: str, target_jobs: list) -> dict:
    """
    å°†ç”¨æˆ·è¾“å…¥çš„å²—ä½åç§°è§£æä¸ºå¯ç”¨çš„å²—ä½é…ç½®ï¼Œæ”¯æŒä»»æ„å²—ä½åï¼š
    1. ç²¾ç¡®åŒ¹é…é…ç½®ä¸­çš„ name
    2. æ¨¡ç³ŠåŒ¹é…ï¼šé…ç½® name æˆ– csv_keywords åŒ…å«ç”¨æˆ·è¾“å…¥ã€æˆ–ç”¨æˆ·è¾“å…¥åŒ…å«é…ç½®å…³é”®è¯
    3. å…œåº•ï¼šæŒ‰å¸¸è§å…³é”®è¯é€‰æœ€ç›¸è¿‘æ¨¡æ¿ï¼ˆå¦‚ã€Œç®—æ³•ã€â†’ æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆï¼‰
    """
    if not job_name or not target_jobs:
        return None
    job_name = (job_name or "").strip()
    # 1) ç²¾ç¡®åŒ¹é…
    exact = next((j for j in target_jobs if j.get("name") == job_name), None)
    if exact:
        return dict(exact)

    # 2) æ¨¡ç³ŠåŒ¹é…ï¼šç”¨æˆ·è¾“å…¥åŒ…å«é…ç½®åä¸­çš„æŸæ®µï¼Œæˆ–é…ç½®ååŒ…å«ç”¨æˆ·è¾“å…¥
    for j in target_jobs:
        name = (j.get("name") or "")
        if job_name in name or name in job_name:
            cfg = dict(j)
            cfg["name"] = job_name
            return cfg
    # é…ç½®çš„ csv_keywords ä¸­ä»»æ„å…³é”®è¯å‡ºç°åœ¨ç”¨æˆ·è¾“å…¥é‡Œ
    for j in target_jobs:
        keywords = j.get("csv_keywords") or []
        if any(kw and str(kw).lower() in job_name.lower() for kw in keywords):
            cfg = dict(j)
            cfg["name"] = job_name
            return cfg
    # é…ç½® name çš„æŸéƒ¨åˆ†ï¼ˆå¦‚ "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ" çš„ "ç®—æ³•å·¥ç¨‹å¸ˆ"ï¼‰åœ¨ç”¨æˆ·è¾“å…¥é‡Œ
    for j in target_jobs:
        name = (j.get("name") or "")
        for part in name.replace("ã€", "/").split("/"):
            part = part.strip()
            if part and part in job_name:
                cfg = dict(j)
                cfg["name"] = job_name
                return cfg

    # 3) å…œåº•ï¼šæŒ‰å…³é”®è¯é€‰æœ€ç›¸è¿‘æ¨¡æ¿
    fallback_map = [
        ("ç®—æ³•", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("æœºå™¨å­¦ä¹ ", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("å¤§æ¨¡å‹", "å¤§æ¨¡å‹/AIGCåº”ç”¨å·¥ç¨‹å¸ˆ"),
        ("ç®—æ³•å·¥ç¨‹å¸ˆ", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("å¼€å‘", "Javaåç«¯å¼€å‘å·¥ç¨‹å¸ˆ"),
        ("å‰ç«¯", "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"),
        ("æµ‹è¯•", "è½¯ä»¶æµ‹è¯•å·¥ç¨‹å¸ˆ"),
        ("äº§å“", "äº§å“ç»ç†"),
        ("æ•°æ®", "æ•°æ®åˆ†æå¸ˆ"),
        ("è¿ç»´", "Linuxè¿ç»´å·¥ç¨‹å¸ˆ"),
    ]
    for keyword, template_name in fallback_map:
        if keyword in job_name:
            matched = next((j for j in target_jobs if j.get("name") == template_name), None)
            if matched:
                cfg = dict(matched)
                cfg["name"] = job_name
                return cfg
    # æœ€ç»ˆå…œåº•ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®ä½œä¸ºé€šç”¨æ¨¡æ¿
    first = target_jobs[0]
    cfg = dict(first)
    cfg["name"] = job_name
    return cfg


def _synthetic_job_id(job_name: str, task_id: str) -> str:
    """ä»»æ„å²—ä½åä½¿ç”¨ç‹¬ç«‹ job_idï¼Œé¿å…è¦†ç›–æ¨¡æ¿é…ç½®çš„å­˜å‚¨ã€‚"""
    import re
    slug = re.sub(r"[^\w\u4e00-\u9fff]", "_", (job_name or "")[:24]).strip("_") or "unknown"
    return f"gen_{slug}_{task_id[-6:]}" if task_id else f"gen_{slug}"


@job_bp.route("/ai-generate-profile", methods=["POST"])
def ai_generate_profile():
    """
    ä½¿ç”¨AIå¤§æ¨¡å‹åˆ†æå²—ä½æ•°æ®ï¼Œç”Ÿæˆæ–°çš„å²—ä½ç”»åƒï¼ˆå¼‚æ­¥ï¼‰
    è¯·æ±‚ä½“ï¼ˆå¯¹åº”APIæ–‡æ¡£4.4ï¼‰ï¼š
      { job_name, job_descriptions: [...], sample_size }
    job_descriptions ä¸ºå‰ç«¯ä¼ å…¥çš„JDæ–‡æœ¬æ•°ç»„ï¼ˆå¯é€‰ï¼‰ï¼›
    è‹¥ä¸ä¼ ï¼Œåˆ™è‡ªåŠ¨ä»å†…éƒ¨CSVæ•°æ®é›†ä¸­æ£€ç´¢å¯¹åº”JDã€‚
    æ”¯æŒä»»æ„å²—ä½åç§°ï¼šæœªç²¾ç¡®åŒ¹é…æ—¶æŒ‰æ¨¡ç³ŠåŒ¹é…æˆ–é€šç”¨æ¨¡æ¿ç”Ÿæˆã€‚
    """
    try:
        body = request.get_json(silent=True) or {}
        job_name         = body.get("job_name")           # å•ä¸ªå²—ä½åç§°
        job_names        = body.get("job_names", [])      # æ‰¹é‡å²—ä½ï¼ˆå¯¹åº”8.2ï¼‰
        job_descriptions = body.get("job_descriptions", [])  # å‰ç«¯ä¼ å…¥JDåˆ—è¡¨ï¼ˆ4.4ï¼‰
        sample_size      = int(body.get("sample_size", 30))

        if not job_name and not job_names:
            return error_response(400, "è¯·æä¾› job_name æˆ– job_names å‚æ•°")

        service = get_job_profile_service()
        target_jobs = job_profile_conf.get("target_jobs", [])
        ts = datetime.now().strftime("%Y%m%d%H%M%S")

        if job_name:
            # â”€â”€ å•ä¸ªå²—ä½ç”Ÿæˆï¼ˆæ”¯æŒä»»æ„å²—ä½åï¼šæ¨¡ç³ŠåŒ¹é…æˆ–å…œåº•æ¨¡æ¿ï¼‰â”€â”€
            task_id = f"job_gen_{ts}_{(job_name or '')[:8]}"
            job_config = _resolve_job_config(job_name, target_jobs)
            if not job_config:
                return error_response(404, f"æœªæ‰¾åˆ°å¯ç”¨çš„å²—ä½é…ç½®ï¼ˆtarget_jobs ä¸ºç©ºï¼‰")

            # ç²¾ç¡®åŒ¹é…ï¼ˆé…ç½®ä¸­å·²æœ‰è¯¥å²—ä½åï¼‰ä¿ç•™åŸ job_idï¼›æ¨¡ç³Š/å…œåº•åŒ¹é…ç”¨ç‹¬ç«‹ job_id å­˜ç»“æœï¼Œé¿å…è¦†ç›–æ¨¡æ¿
            is_exact = any(j.get("name") == job_name for j in target_jobs)
            if not is_exact:
                job_config["job_id"] = _synthetic_job_id(job_name, task_id)
            job_config["name"] = job_name

            def _generate_single():
                cfg = dict(job_config)
                if job_descriptions:
                    cfg["external_jd_list"] = job_descriptions[:sample_size]
                profile = service.generate_profile(cfg)
                service.profiles_store[cfg["job_id"]] = profile
                from job_profile.job_profile_service import _save_profiles_store
                _save_profiles_store(service.profiles_store)
                return profile

            _run_task_async(task_id, _generate_single)

            return success_response({
                "task_id": task_id,
                "status": "processing",
                "estimated_time": 30,
                "job_name": job_name
            }, msg="AIç”»åƒç”Ÿæˆä¸­...")

        else:
            # â”€â”€ æ‰¹é‡ç”Ÿæˆï¼ˆåŒæ ·æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰â”€â”€
            task_id = f"batch_gen_{ts}"

            def _generate_batch():
                results = {}
                errors = {}
                for name in job_names:
                    cfg = _resolve_job_config(name, target_jobs)
                    if not cfg:
                        errors[name] = "æœªæ‰¾åˆ°é…ç½®"
                        continue
                    cfg["name"] = name
                    tid = f"batch_{ts}_{name[:8]}"
                    cfg["job_id"] = _synthetic_job_id(name, tid)
                    try:
                        profile = service.generate_profile(dict(cfg))
                        service.profiles_store[cfg["job_id"]] = profile
                        results[name] = cfg["job_id"]
                    except Exception as ex:
                        errors[name] = str(ex)
                from job_profile.job_profile_service import _save_profiles_store
                _save_profiles_store(service.profiles_store)
                return {"results": results, "errors": errors}

            _run_task_async(task_id, _generate_batch)

            return success_response({
                "task_id": task_id,
                "total_jobs": len(job_names),
                "status": "processing",
                "estimated_time": f"{len(job_names) * 30}ç§’"
            }, msg="æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨")

    except Exception as e:
        logger.error(f"[API] /job/ai-generate-profile å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.5 è·å–AIç”Ÿæˆç»“æœ
# POST /api/v1/job/ai-generate-result
# ============================================================
@job_bp.route("/ai-generate-result", methods=["POST"])
def get_ai_generate_result():
    """
    è·å–AIå²—ä½ç”»åƒç”Ÿæˆç»“æœ
    è¯·æ±‚ä½“ï¼š{ task_id }
    """
    try:
        body = request.get_json(silent=True) or {}
        task_id = body.get("task_id")

        if not task_id:
            return error_response(400, "è¯·æä¾› task_id å‚æ•°")

        if task_id not in _tasks:
            _load_persisted_tasks()
        if task_id not in _tasks:
            return error_response(404, f"ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ: {task_id}")

        task = _tasks[task_id]
        response_data = {
            "task_id": task_id,
            "status": task["status"],  # pending / processing / completed / failed
        }

        if task["status"] == "completed":
            raw = task["result"]
            # å¯¹åº”APIæ–‡æ¡£4.5å“åº”æ ¼å¼ï¼šjob_profile + ai_confidence + data_sources
            response_data["job_profile"]  = raw if isinstance(raw, dict) else raw
            response_data["ai_confidence"] = (
                raw.get("_ai_confidence", 0.88)
                if isinstance(raw, dict) else 0.88
            )
            response_data["data_sources"] = {
                "total_samples":  (raw.get("csv_sample_count", 0)
                                   if isinstance(raw, dict) else 0),
                "valid_samples":  (raw.get("csv_sample_count", 0)
                                   if isinstance(raw, dict) else 0),
                "analysis_date":  datetime.now().strftime("%Y-%m-%d"),
                "data_source":    (raw.get("data_source", "")
                                   if isinstance(raw, dict) else ""),
            }
        elif task["status"] == "failed":
            response_data["error"] = task["error"]

        return success_response(response_data)

    except Exception as e:
        logger.error(f"[API] /job/ai-generate-result å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# é¢å¤–ï¼šè·å–å®Œæ•´å²—ä½å…³è”å›¾è°±ï¼ˆå…¨å±€ï¼‰
# POST /api/v1/job/full-graph
# ============================================================
@job_bp.route("/full-graph", methods=["POST"])
def get_full_graph():
    """
    è·å–å…¨é‡å²—ä½å…³è”å›¾è°±ï¼ˆåŒ…å«æ‰€æœ‰å‚ç›´+æ¢å²—è·¯å¾„ï¼‰
    """
    try:
        graph_service = get_job_graph_service()
        graph = graph_service.get_full_graph()
        return success_response(graph)
    except Exception as e:
        logger.error(f"[API] /job/full-graph å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 8.2 è§¦å‘å²—ä½ç”»åƒç”Ÿæˆï¼ˆå¯¹åº”APIæ–‡æ¡£ 8.2ï¼‰
# POST /api/v1/system/generate-job-profiles
# æ³¨ï¼šåŒæ—¶ä¿ç•™ /job/batch-generate ä½œä¸ºå†…éƒ¨å…¼å®¹è·¯å¾„
# ============================================================
@job_bp.route("/batch-generate", methods=["POST"])
def _batch_generate_compat():
    """å…¼å®¹æ—§è·¯å¾„ï¼Œè½¬å‘è‡³æ ‡å‡†è·¯å¾„å¤„ç†å‡½æ•°"""
    return _do_batch_generate()


# æ ‡å‡†è·¯å¾„ï¼ˆå¯¹åº”APIæ–‡æ¡£8.2ï¼‰
from flask import current_app as _app

def _register_system_route(app):
    """åœ¨ app ä¸Šæ³¨å†Œ /api/v1/system è·¯ç”±ï¼ˆç”± app.py è°ƒç”¨ï¼‰"""
    @app.route("/api/v1/system/generate-job-profiles", methods=["POST"])
    def system_generate_job_profiles():
        """
        8.2 ç®¡ç†å‘˜è§¦å‘æ‰¹é‡å²—ä½ç”»åƒç”Ÿæˆï¼ˆå¯¹åº”APIæ–‡æ¡£8.2ï¼‰
        è¯·æ±‚ä½“ï¼š{ admin_id, job_names: [...], sample_size_per_job }
        admin_id ä¸ºå¿…å¡«ï¼Œæ ‡å‡†è·¯å¾„åœ¨æ­¤æ ¡éªŒæƒé™ã€‚
        """
        body = request.get_json(silent=True) or {}
        admin_id = body.get("admin_id")
        if admin_id is None:
            return error_response(400, "è¯·æä¾› admin_id å‚æ•°")
        return _do_batch_generate()


def _do_batch_generate():
    """
    æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é¢„é…ç½®å²—ä½çš„ç”»åƒï¼ˆå†…éƒ¨å®ç°ï¼Œä¸å«æƒé™æ ¡éªŒï¼‰
    ä¾›æ ‡å‡†è·¯å¾„ /system/generate-job-profiles å’Œå…¼å®¹è·¯å¾„ /job/batch-generate å…±ç”¨ã€‚
    è¯·æ±‚ä½“ï¼š{ force_regenerate }
    """
    try:
        body = request.get_json(silent=True) or {}
        force = body.get("force_regenerate", False)

        ts = datetime.now().strftime("%Y%m%d%H%M%S")
        task_id = f"batch_gen_all_{ts}"

        service = get_job_profile_service()
        target_jobs = job_profile_conf.get("target_jobs", [])

        def _generate_all():
            return service.generate_all_profiles(force_regenerate=force)

        _run_task_async(task_id, _generate_all)

        return success_response({
            "task_id": task_id,
            "total_jobs": len(target_jobs),
            "status": "processing",
            "estimated_time": f"çº¦{len(target_jobs) * 30}ç§’",
            "job_names": [j["name"] for j in target_jobs]
        }, msg="æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨")

    except Exception as e:
        logger.error(f"[API] /job/batch-generate å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")
