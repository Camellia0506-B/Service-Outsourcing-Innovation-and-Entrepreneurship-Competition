"""
Â≤ó‰ΩçÁîªÂÉèÊúçÂä°Ê®°Âùó v3 - Êï∞ÊçÆÈõÜ‰ºòÂÖàÁ≠ñÁï•
=============================================
ÁîüÊàêÁ≠ñÁï•Ôºö
  „Äê‰ºòÂÖà„ÄëÊï∞ÊçÆÈõÜJDÂàÜÊûêÔºö‰ªéCSVÊèêÂèñÂåπÈÖçÂ≤ó‰ΩçÁöÑËÅå‰ΩçÊèèËø∞(JD)ÔºåÂñÇÁªôÊ®°ÂûãÂàÜÊûêÊèêÁÇº
  „ÄêÂÖúÂ∫ï„ÄëÊ®°ÂûãÁü•ËØÜÁîüÊàêÔºöÊï∞ÊçÆÈõÜÊó†ÂåπÈÖçÊï∞ÊçÆÊó∂ÔºåÁî±Ê®°ÂûãÂá≠Ë°å‰∏öËÆ§Áü•ÁîüÊàê

‰∏é‰∏ä‰∏ÄÁâàÊú¨ÁöÑÊ†∏ÂøÉÂå∫Âà´Ôºö
  - ‰πãÂâçÔºö‰ªéCSVÂè™ÊèêÂèñËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏3‰∏™Â≠óÊÆµÔºàËæÖÂä©‰ø°ÊÅØÔºâ
  - Áé∞Âú®Ôºö‰ªéCSVÊèêÂèñÂÆåÊï¥ËÅå‰ΩçÊèèËø∞JDÔºà‰∏ªË¶Å‰ø°ÊÅØÊ∫êÔºâÔºåÊ®°ÂûãÂü∫‰∫éÁúüÂÆûJDÊèêÁÇºÁîªÂÉè

CSVÂ≠óÊÆµËØ¥ÊòéÔºàÊù•Ëá™Ê±ÇËÅåÂ≤ó‰Ωç‰ø°ÊÅØÊï∞ÊçÆ.csvÔºâÔºö
  ËÅå‰Ωç‰ª£Á†Å / ËÅå‰ΩçÂêçÁß∞ / Â∑•‰ΩúÂú∞ÂùÄ / Ëñ™ËµÑËåÉÂõ¥ /
  ‰ºÅ‰∏öÊÄßË¥® / ÂÖ¨Âè∏ÂÖ®Áß∞ / ‰∫∫ÂëòËßÑÊ®° / ÊâÄÂ±ûË°å‰∏ö / ËÅå‰ΩçÊèèËø∞ / ÂÖ¨Âè∏ÁÆÄ‰ªã

ÂØπÂ∫îAPIÔºö
  4.1 POST /job/profiles
  4.2 POST /job/profile/detail
  4.4 POST /job/ai-generate-profile
"""

import csv
import json
import os
import re
from datetime import datetime
from typing import Optional

import yaml
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate

from utils.logger_handler import logger
from utils.path_tool import get_abs_path


# ========== Âä†ËΩΩÈÖçÁΩÆ ==========
def _load_job_profile_config() -> dict:
    config_path = get_abs_path("config/job_profile.yml")
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.load(f, Loader=yaml.FullLoader)


job_profile_conf = _load_job_profile_config()


# ========== Â∑•ÂÖ∑ÂáΩÊï∞ ==========

def _load_prompt(prompt_key: str) -> str:
    prompts_config_path = get_abs_path("config/prompts.yml")
    with open(prompts_config_path, "r", encoding="utf-8") as f:
        prompts_conf = yaml.load(f, Loader=yaml.FullLoader)
    path = get_abs_path(prompts_conf[prompt_key])
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def _ensure_store_dir() -> str:
    store_path = get_abs_path(job_profile_conf["job_profiles_store"])
    os.makedirs(os.path.dirname(store_path), exist_ok=True)
    return store_path


def _load_profiles_store() -> dict:
    store_path = _ensure_store_dir()
    if not os.path.exists(store_path):
        return {}
    with open(store_path, "r", encoding="utf-8") as f:
        return json.load(f)


def _save_profiles_store(profiles: dict):
    store_path = _ensure_store_dir()
    with open(store_path, "w", encoding="utf-8") as f:
        json.dump(profiles, f, ensure_ascii=False, indent=2)


def _extract_json(text: str) -> dict:
    """‰ªéÊ®°ÂûãËæìÂá∫‰∏≠ÊèêÂèñJSONÔºåÂÖºÂÆπmarkdown‰ª£Á†ÅÂùóÂåÖË£π"""
    text = text.strip()
    text = re.sub(r"^```json\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"^```\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"\s*```$", "", text, flags=re.MULTILINE)
    text = text.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        match = re.search(r"\{[\s\S]+\}", text)
        if match:
            try:
                return json.loads(match.group())
            except Exception:
                pass
        raise ValueError(f"Ê®°ÂûãËæìÂá∫Êó†Ê≥ïËß£Êûê‰∏∫JSONÔºåÁâáÊÆµ: {text[:300]}")


# ========== Êï∞ÊçÆÈõÜÊèêÂèñÂô®ÔºàÊï∞ÊçÆ‰ºòÂÖàÁ≠ñÁï•ÁöÑÊ†∏ÂøÉÔºâ==========

class CsvDataExtractor:
    """
    ‰ªéCSVÊï∞ÊçÆÈõÜ‰∏≠ÊèêÂèñÂ≤ó‰ΩçÁöÑÂÆåÊï¥‰ø°ÊÅØ„ÄÇ

    Á≠ñÁï•ËØ¥ÊòéÔºö
      - ÊèêÂèñÂÆåÊï¥ÁöÑËÅå‰ΩçÊèèËø∞(JD)ÊñáÊú¨Ôºå‰Ωú‰∏∫Ê®°ÂûãÂàÜÊûêÁöÑ‰∏ªË¶ÅÂéüÊñô
      - ÊèêÂèñËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏Á≠âÁªìÊûÑÂåñ‰ø°ÊÅØ‰Ωú‰∏∫ËæÖÂä©
      - ÊúâÊï∞ÊçÆ ‚Üí Âü∫‰∫éÁúüÂÆûJDÁîüÊàêÁîªÂÉèÔºàÊï∞ÊçÆÈ©±Âä®Ôºâ
      - Êó†Êï∞ÊçÆ ‚Üí Ê†áËÆ∞‰∏∫"Êó†ÂåπÈÖçÊï∞ÊçÆ"Ôºå‰∫§Áî±Ê®°ÂûãÁü•ËØÜÁîüÊàêÔºàÊ®°ÂûãÂÖúÂ∫ïÔºâ
    """

    # CSVÂêÑÂ≠óÊÆµÂêçÔºà‰∏éÂÆûÈôÖÊñá‰ª∂‰øùÊåÅ‰∏ÄËá¥Ôºâ
    FIELD_NAME      = "ËÅå‰ΩçÂêçÁß∞"
    FIELD_ADDRESS   = "Â∑•‰ΩúÂú∞ÂùÄ"
    FIELD_SALARY    = "Ëñ™ËµÑËåÉÂõ¥"
    FIELD_COMPANY   = "ÂÖ¨Âè∏ÂÖ®Áß∞"
    FIELD_NATURE    = "‰ºÅ‰∏öÊÄßË¥®"
    FIELD_SCALE     = "‰∫∫ÂëòËßÑÊ®°"
    FIELD_INDUSTRY  = "ÊâÄÂ±ûË°å‰∏ö"
    FIELD_JD        = "ËÅå‰ΩçÊèèËø∞"

    def __init__(self):
        self.data_path = get_abs_path(job_profile_conf["job_data_path"])
        self._all_rows: Optional[list] = None

    def _load_all(self) -> list:
        if self._all_rows is not None:
            return self._all_rows
        if not os.path.exists(self.data_path):
            logger.warning(f"[CsvDataExtractor] CSVÊñá‰ª∂‰∏çÂ≠òÂú®: {self.data_path}")
            self._all_rows = []
            return []
        rows = []
        with open(self.data_path, "r", encoding="utf-8-sig") as f:
            for row in csv.DictReader(f):
                rows.append(row)
        self._all_rows = rows
        logger.info(f"[CsvDataExtractor] Âä†ËΩΩCSV: {len(rows)}Êù°")
        return rows

    def search(self, keywords: list[str], max_count: int = 10) -> list[dict]:
        """
        ÂÖ≥ÈîÆËØçÂåπÈÖçËÅå‰ΩçÂêçÁß∞ÔºåËøîÂõûÂåπÈÖçÂà∞ÁöÑÂÆåÊï¥Ë°åÊï∞ÊçÆÔºàÂê´JDÔºâ„ÄÇ
        Â§ßÂ∞èÂÜô‰∏çÊïèÊÑüÔºå‰ªªÊÑèÂÖ≥ÈîÆËØçÂëΩ‰∏≠Âç≥ÁÆóÂåπÈÖç„ÄÇ
        """
        all_rows = self._load_all()
        keywords_lower = [kw.lower() for kw in keywords]
        matched = []
        for row in all_rows:
            name = row.get(self.FIELD_NAME, "").lower()
            if any(kw in name for kw in keywords_lower):
                matched.append(row)
            if len(matched) >= max_count:
                break
        return matched

    def build_jd_block(self, matched_rows: list[dict]) -> str:
        """
        Â∞ÜÂåπÈÖçÂà∞ÁöÑËÅå‰ΩçÊï∞ÊçÆÁªÑË£ÖÊàêÁªìÊûÑÂåñÊñáÊú¨ÂùóÔºå‰æõÊèêÁ§∫ËØçÊ≥®ÂÖ•„ÄÇ
        ÊØèÊù°Êï∞ÊçÆÂåÖÂê´ÔºöËÅå‰ΩçÂêçÁß∞ + Ëñ™ËµÑ + Ë°å‰∏ö + ËÅå‰ΩçÊèèËø∞(ÂÆåÊï¥)
        """
        if not matched_rows:
            return ""  # Ë∞ÉÁî®ÊñπÊ£ÄÊü•Á©∫Â≠óÁ¨¶‰∏≤ÂÜ≥ÂÆöËµ∞Âì™Êù°ÂàÜÊîØ

        blocks = []
        for i, row in enumerate(matched_rows, 1):
            jd_text = row.get(self.FIELD_JD, "").strip()
            # Êà™Êñ≠ËøáÈïøÁöÑJDÔºàÈò≤Ê≠¢promptËøáÂ§ßÔºâÔºå‰øùÁïôÂâç1500Â≠ó
            if len(jd_text) > 1500:
                jd_text = jd_text[:1500] + "‚Ä¶‚Ä¶ÔºàÊà™Êñ≠Ôºâ"
            block = (
                f"„ÄêÊ†∑Êú¨{i}„Äë\n"
                f"  ËÅå‰ΩçÂêçÁß∞Ôºö{row.get(self.FIELD_NAME, '')}\n"
                f"  Ëñ™ËµÑËåÉÂõ¥Ôºö{row.get(self.FIELD_SALARY, 'Êú™Áü•')}\n"
                f"  ÊâÄÂ±ûË°å‰∏öÔºö{row.get(self.FIELD_INDUSTRY, 'Êú™Áü•')}\n"
                f"  ‰ºÅ‰∏öËßÑÊ®°Ôºö{row.get(self.FIELD_SCALE, 'Êú™Áü•')}\n"
                f"  ËÅå‰ΩçÊèèËø∞Ôºö\n{jd_text}"
            )
            blocks.append(block)

        return "\n\n".join(blocks)

    def get_market_meta(self, matched_rows: list[dict]) -> dict:
        """ÊèêÂèñÁªìÊûÑÂåñÂ∏ÇÂú∫ÂÖÉÊï∞ÊçÆÔºàËñ™ËµÑ/ÂüéÂ∏Ç/ÂÖ¨Âè∏ÔºâÔºåÁî®‰∫éÁîªÂÉèÁöÑmarket_analysisÂ≠óÊÆµ"""
        if not matched_rows:
            return {"salaries": [], "cities": [], "companies": [], "industries": []}
        return {
            "salaries":   list({r.get(self.FIELD_SALARY, "") for r in matched_rows if r.get(self.FIELD_SALARY)}),
            "cities":     list({r.get(self.FIELD_ADDRESS, "").split("¬∑")[0] for r in matched_rows if r.get(self.FIELD_ADDRESS)}),
            "companies":  list({r.get(self.FIELD_COMPANY, "") for r in matched_rows if r.get(self.FIELD_COMPANY)})[:5],
            "industries": list({r.get(self.FIELD_INDUSTRY, "") for r in matched_rows if r.get(self.FIELD_INDUSTRY)}),
        }


# ========== Â≤ó‰ΩçÁîªÂÉèÁîüÊàêÊúçÂä° ==========

class JobProfileService:
    """
    Â≤ó‰ΩçÁîªÂÉèÁîüÊàê‰∏éÁÆ°ÁêÜÊúçÂä°

    ÁîüÊàêÁ≠ñÁï•ÔºàÊï∞ÊçÆÈõÜ‰ºòÂÖàÔºâÔºö
      ÊúâÂåπÈÖçJD ‚Üí Ê®°ÂûãÂü∫‰∫éÁúüÂÆûJDÊèêÁÇºÊ†áÂáÜÂåñÁîªÂÉè
      Êó†ÂåπÈÖçJD ‚Üí Ê®°ÂûãÂá≠Ë°å‰∏öËÆ§Áü•ÁîüÊàêÔºàÂÖúÂ∫ïÔºâ
    """

    def __init__(self):
        self.extractor = CsvDataExtractor()
        self.profiles_store = _load_profiles_store()
        self.model = self._init_model()

    def _init_model(self):
        try:
            from model.factory import chat_model
            return chat_model
        except ImportError:
            from langchain_community.chat_models.tongyi import ChatTongyi
            from utils.config_handler import rag_conf
            return ChatTongyi(model=rag_conf["chat_model_name"])

    def _build_chain(self):
        prompt_text = _load_prompt("job_profile_prompt_path")
        template = PromptTemplate.from_template(prompt_text)
        return template | self.model | StrOutputParser()

    # ===================================================
    # Ê†∏ÂøÉÔºöÁîüÊàêÂçï‰∏™Â≤ó‰ΩçÁîªÂÉè
    # ===================================================
    def generate_profile(self, job_config: dict) -> dict:
        """
        ÁîüÊàêÂ≤ó‰ΩçÁîªÂÉèÔºö
          1. ‰ªéCSVÊêúÁ¥¢ÂåπÈÖçÁöÑJDÊï∞ÊçÆ
          2. ÊúâÊï∞ÊçÆ ‚Üí Ê≥®ÂÖ•JDÊñáÊú¨ÔºåËÆ©Ê®°ÂûãÂü∫‰∫éÁúüÂÆûÊï∞ÊçÆÊèêÁÇº
             Êó†Êï∞ÊçÆ ‚Üí Ê≥®ÂÖ•ÊòéÁ°ÆÊèêÁ§∫ÔºåËÆ©Ê®°ÂûãÂá≠Áü•ËØÜÁîüÊàêÔºàÂÖúÂ∫ïÔºâ
          3. Ë∞ÉÁî®Ê®°ÂûãÔºåËß£ÊûêËæìÂá∫JSON
          4. Ë°•ÂÖÖÂÖÉÊï∞ÊçÆÂπ∂Â≠òÂÇ®
        """
        job_id    = job_config["job_id"]
        job_name  = job_config["name"]
        category  = job_config.get("category", "")
        keywords  = job_config.get("csv_keywords", [job_name])
        weights   = job_config.get("dimension_weights", {})
        max_count = job_profile_conf.get("max_csv_sample_per_job", 10)

        logger.info(f"[JobProfileService] ÂºÄÂßãÁîüÊàê: {job_name} ({job_id})")

        # Step 1: Ê£ÄÁ¥¢CSVÊï∞ÊçÆÈõÜ
        matched_rows = self.extractor.search(keywords, max_count)
        jd_block     = self.extractor.build_jd_block(matched_rows)
        market_meta  = self.extractor.get_market_meta(matched_rows)

        logger.info(f"  CSVÊ£ÄÁ¥¢: {len(matched_rows)}Êù°ÂåπÈÖçÊï∞ÊçÆ")

        # Step 2: ÊûÑÂª∫Êï∞ÊçÆÊ≥®ÂÖ•ÊñáÊú¨Ôºà‰∏§Êù°ÂàÜÊîØÊ∏ÖÊô∞Ôºâ
        if jd_block:
            # ‚òÖ ÂàÜÊîØAÔºöÊúâÊï∞ÊçÆÈõÜÊï∞ÊçÆÔºåÂü∫‰∫éÁúüÂÆûJDÁîüÊàê
            data_section = (
                f"[Êï∞ÊçÆÊù•Ê∫êÔºöÊï∞ÊçÆÈõÜ | ÂåπÈÖçÊù°Êï∞Ôºö{len(matched_rows)}]\n"
                f"‰ª•‰∏ãÊòØÊï∞ÊçÆÈõÜ‰∏≠Ê£ÄÁ¥¢Âà∞ÁöÑÁúüÂÆûÊãõËÅòJDÔºåËØ∑‰∏•Ê†ºÂü∫‰∫éËøô‰∫õJDÂÜÖÂÆπÊèêÁÇºÂ≤ó‰ΩçÁîªÂÉèÔºå"
                f"‰∏çË¶ÅËá™Áî±ÂèëÊå•Ë∂ÖÂá∫JDËåÉÂõ¥ÁöÑÂÜÖÂÆπÔºö\n\n"
                f"{jd_block}"
            )
            data_source_label = f"Êï∞ÊçÆÈõÜJDÂàÜÊûêÔºà{len(matched_rows)}Êù°Ê†∑Êú¨Ôºâ"
        else:
            # ‚òÖ ÂàÜÊîØBÔºöÊó†ÂåπÈÖçÊï∞ÊçÆÔºåÊ®°ÂûãÁü•ËØÜÂÖúÂ∫ï
            data_section = (
                f"[Êï∞ÊçÆÊù•Ê∫êÔºöÊ®°ÂûãÁü•ËØÜ | Êï∞ÊçÆÈõÜÊó†ÂåπÈÖç]\n"
                f"Êï∞ÊçÆÈõÜ‰∏≠Êú™Ê£ÄÁ¥¢Âà∞„Äê{job_name}„ÄëÁöÑÁõ∏ÂÖ≥ÊãõËÅòÊï∞ÊçÆ„ÄÇ\n"
                f"ËØ∑ÂÆåÂÖ®‰æùÊçÆ‰Ω†ÂØπ‰∏≠ÂõΩITË°å‰∏öÁöÑ‰∏ì‰∏öËÆ§Áü•ÔºåÊåâ2024-2025Âπ¥Â∏ÇÂú∫Ê†áÂáÜÁîüÊàêÁîªÂÉè„ÄÇ\n"
                f"Ëñ™ËµÑÂèÇÁÖß‰∏ÄÁ∫øÂüéÂ∏ÇÔºàÂåó‰∫¨/‰∏äÊµ∑/Ê∑±Âú≥/Êù≠Â∑ûÔºâË°åÊÉÖ„ÄÇ"
            )
            data_source_label = "Ê®°ÂûãË°å‰∏öÁü•ËØÜÁîüÊàêÔºàÊï∞ÊçÆÈõÜÊó†ÂåπÈÖçÔºâ"

        # Step 3: Ë∞ÉÁî®Ê®°Âûã
        chain = self._build_chain()
        raw_output = chain.invoke({
            "job_name":     job_name,
            "job_id":       job_id,
            "category":     category,
            "data_section": data_section,
            "dim_weights":  json.dumps(weights, ensure_ascii=False),
        })

        # Step 4: Ëß£ÊûêJSON
        profile = _extract_json(raw_output)

        # Step 5: Ê≥®ÂÖ•/Ê†°È™åÂÖ≥ÈîÆÂÖÉÊï∞ÊçÆ
        profile.setdefault("job_id",   job_id)
        profile.setdefault("job_name", job_name)
        profile.setdefault("category", category)
        profile["data_source"]      = data_source_label
        profile["csv_sample_count"] = len(matched_rows)
        profile["csv_market_meta"]  = market_meta
        profile["created_at"]       = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        profile["updated_at"]       = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        profile["status"]           = "completed"
        profile["dimension_weights"] = weights

        logger.info(f"  ‚úÖ ÁîªÂÉèÁîüÊàêÂÆåÊàê: {job_name} | Êù•Ê∫ê: {data_source_label}")
        return profile

    # ===================================================
    # ÊâπÈáèÁîüÊàê
    # ===================================================
    def generate_all_profiles(self, force_regenerate: bool = False) -> dict:
        target_jobs = job_profile_conf.get("target_jobs", [])
        results, errors = {}, {}

        for i, job_config in enumerate(target_jobs, 1):
            job_id   = job_config["job_id"]
            job_name = job_config["name"]
            logger.info(f"[ÊâπÈáèÁîüÊàê] ({i}/{len(target_jobs)}) {job_name}")

            if not force_regenerate and job_id in self.profiles_store:
                logger.info(f"  Ë∑≥ËøáÔºàÂ∑≤ÊúâÁºìÂ≠òÔºâ")
                results[job_id] = self.profiles_store[job_id]
                continue

            try:
                profile = self.generate_profile(job_config)
                self.profiles_store[job_id] = profile
                results[job_id] = profile
                _save_profiles_store(self.profiles_store)
            except Exception as e:
                logger.error(f"  Â§±Ë¥•: {e}", exc_info=True)
                errors[job_id] = str(e)

        return {
            "results": results, "errors": errors,
            "total": len(target_jobs),
            "success_count": len(results), "error_count": len(errors),
        }

    def generate_by_category(self, category: str, force_regenerate: bool = False) -> dict:
        target_jobs = [j for j in job_profile_conf.get("target_jobs", [])
                       if j.get("category") == category]
        results, errors = {}, {}
        for job_config in target_jobs:
            job_id = job_config["job_id"]
            if not force_regenerate and job_id in self.profiles_store:
                results[job_id] = self.profiles_store[job_id]
                continue
            try:
                profile = self.generate_profile(job_config)
                self.profiles_store[job_id] = profile
                results[job_id] = profile
                _save_profiles_store(self.profiles_store)
            except Exception as e:
                errors[job_id] = str(e)
        return {"results": results, "errors": errors,
                "success_count": len(results), "error_count": len(errors)}

    # ===================================================
    # Êü•ËØ¢Êé•Âè£
    # ===================================================
    def get_profile_list(self, page=1, size=20, keyword=None,
                         industry=None, level=None, category=None) -> dict:
        profiles = list(self.profiles_store.values())
        if keyword:
            profiles = [p for p in profiles if keyword in p.get("job_name", "")
                        or keyword in p.get("category", "")]
        if industry:
            profiles = [p for p in profiles
                        if industry in p.get("basic_info", {}).get("industry", "")]
        if level:
            profiles = [p for p in profiles
                        if level in p.get("basic_info", {}).get("level_range", [])]
        if category:
            profiles = [p for p in profiles if p.get("category") == category]

        total = len(profiles)
        page_data = profiles[(page - 1) * size: page * size]
        return {
            "total": total, "page": page, "size": size,
            "list": [{
                "job_id":       p.get("job_id"),
                "job_name":     p.get("job_name"),
                "job_code":     p.get("job_code"),
                "category":     p.get("category"),
                "industry":     p.get("basic_info", {}).get("industry"),
                "level_range":  p.get("basic_info", {}).get("level_range", []),
                "avg_salary":   p.get("basic_info", {}).get("salary_range", {}).get("junior", ""),
                "description":  p.get("basic_info", {}).get("description"),
                "demand_score": p.get("market_analysis", {}).get("demand_score", 0),
                "growth_trend": p.get("market_analysis", {}).get("growth_trend"),
                "tags":         p.get("market_analysis", {}).get("tags", []),
                "data_source":  p.get("data_source"),
                "created_at":   p.get("created_at"),
            } for p in page_data],
        }

    def get_profile_detail(self, job_id: str) -> Optional[dict]:
        return self.profiles_store.get(job_id)

    def get_profile_by_name(self, job_name: str) -> Optional[dict]:
        for p in self.profiles_store.values():
            if p.get("job_name") == job_name:
                return p
        for p in self.profiles_store.values():
            if job_name in p.get("job_name", ""):
                return p
        return None

    def get_category_summary(self) -> dict:
        target_jobs = job_profile_conf.get("target_jobs", [])
        summary = {}
        for job_config in target_jobs:
            cat = job_config.get("category", "Êú™ÂàÜÁ±ª")
            if cat not in summary:
                summary[cat] = {"total": 0, "generated": 0, "jobs": []}
            summary[cat]["total"] += 1
            done = job_config["job_id"] in self.profiles_store
            if done:
                summary[cat]["generated"] += 1
            profile = self.profiles_store.get(job_config["job_id"], {})
            summary[cat]["jobs"].append({
                "job_id":      job_config["job_id"],
                "name":        job_config["name"],
                "done":        done,
                "data_source": profile.get("data_source", "‚Äî"),
                "csv_samples": profile.get("csv_sample_count", 0),
            })
        return summary

    def preview_csv_match(self) -> dict:
        """È¢ÑËßàÂêÑÂ≤ó‰ΩçËÉΩ‰ªéCSV‰∏≠ÂåπÈÖçÂà∞Â§öÂ∞ëÊù°Êï∞ÊçÆÔºà‰∏çÁîüÊàêÁîªÂÉèÔºåÂè™ÁªüËÆ°Ôºâ"""
        result = {}
        for job_config in job_profile_conf.get("target_jobs", []):
            keywords = job_config.get("csv_keywords", [job_config["name"]])
            matched  = self.extractor.search(keywords, max_count=20)
            result[job_config["job_id"]] = {
                "name":    job_config["name"],
                "matched": len(matched),
                "samples": [r.get("ËÅå‰ΩçÂêçÁß∞", "") for r in matched],
                "strategy": "Êï∞ÊçÆÈõÜJDÂàÜÊûê" if matched else "Ê®°ÂûãÁü•ËØÜÂÖúÂ∫ï",
            }
        return result

    def reload_store(self):
        self.profiles_store = _load_profiles_store()


# ========== Âçï‰æã ==========
_instance: Optional[JobProfileService] = None


def get_job_profile_service() -> JobProfileService:
    global _instance
    if _instance is None:
        _instance = JobProfileService()
    return _instance


# ========== CLI ==========
if __name__ == "__main__":
    import sys
    service = JobProfileService()
    cmd = sys.argv[1] if len(sys.argv) > 1 else "--preview"

    if cmd == "--preview":
        print("=== CSVÂåπÈÖçÈ¢ÑËßàÔºà‰∫ÜËß£Âì™‰∫õÂ≤ó‰ΩçÊúâÁúüÂÆûÊï∞ÊçÆÔºâ===\n")
        preview = service.preview_csv_match()
        for jid, info in preview.items():
            mark = "üìä" if info["matched"] > 0 else "ü§ñ"
            print(f"{mark} {jid} {info['name']:20s} | ÂåπÈÖç{info['matched']:2d}Êù° | {info['strategy']}")
            if info["samples"]:
                print(f"     ÂåπÈÖçÂà∞: {', '.join(info['samples'][:3])}")

    elif cmd == "--status":
        summary = service.get_category_summary()
        for cat, info in summary.items():
            print(f"\n„Äê{cat}„Äë({info['generated']}/{info['total']})")
            for j in info["jobs"]:
                mark = "‚úÖ" if j["done"] else "‚è≥"
                src  = f"[{j['data_source']}]" if j["done"] else ""
                print(f"  {mark} {j['name']} {src}")

    elif cmd == "--generate":
        job_name = sys.argv[2] if len(sys.argv) > 2 else None
        target_jobs = job_profile_conf.get("target_jobs", [])
        cfg = next((j for j in target_jobs if j["name"] == job_name), None)
        if cfg:
            profile = service.generate_profile(cfg)
            service.profiles_store[cfg["job_id"]] = profile
            _save_profiles_store(service.profiles_store)
            print(f"Êù•Ê∫ê: {profile['data_source']}")
            print(f"CSVÊ†∑Êú¨Êï∞: {profile['csv_sample_count']}")
            print(json.dumps(profile, ensure_ascii=False, indent=2)[:2000])
        else:
            print(f"Êú™ÊâæÂà∞: {job_name}")
