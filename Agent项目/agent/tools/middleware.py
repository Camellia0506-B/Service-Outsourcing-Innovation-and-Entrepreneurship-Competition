from typing import Callable
from langchain.agents import AgentState
from langchain.agents.middleware import wrap_tool_call, before_model, dynamic_prompt, ModelRequest
from langchain_core.messages import ToolMessage
from langgraph.prebuilt.tool_node import ToolCallRequest
from langgraph.runtime import Runtime
from langgraph.types import Command
from utils.logger_handler import logger
from utils.prompt_loader import load_system_prompts,load_report_prompts

#å·¥å…·æ‰§è¡Œçš„ç›‘æ§:æ‹¦æˆªçœŸå®å·¥å…·çš„æ‰§è¡Œ
@wrap_tool_call
def monitor_tool(
        request:ToolCallRequest,     #è¯·æ±‚çš„æ•°æ®å°è£…ï¼ˆå…¥å‚ï¼‰
        handler:Callable[[ToolCallRequest],ToolMessage|Command],     #æ‰§è¡Œçš„å‡½æ•°æœ¬èº«ï¼ˆå‡½æ•°ï¼‰
)->ToolMessage | Command:

    logger.info(f"[tool monitor]æ‰§è¡Œå·¥å…·ï¼š{request.tool_call['name']}") #æ‹¿åˆ°æ‰§è¡Œå·¥å…·çš„åç§°
    logger.info(f"[tool monitor]ä¼ å…¥å‚æ•°ï¼š{request.tool_call['args']}")

    try:
        result=handler(request)
        logger.info(f"[tool monitor]å·¥å…·{request.tool_call['name']}è°ƒç”¨æˆåŠŸ")

        #åŠŸèƒ½1ï¼šæ“ä½œruntime
        #fill_context_for_report(æ­¤å‡½æ•°ä½œä¸ºflag)ğŸš©è°ƒç”¨ æ ‡è®°Trueæ³¨å…¥
        if request.tool_call["name"]=="fill_context_for_report":
            request.runtime.context["report"]=True

        return result
    except Exception as e:
        # åŠŸèƒ½2ï¼šæ“ä½œlogger
        logger.error(f"å·¥å…·{request.tool_call['name']}è°ƒç”¨è°ƒç”¨å¤±è´¥ï¼ŒåŸå› ï¼š{str(e)}")
        raise e

#åœ¨æ¨¡å‹æ‰§è¡Œå‰è¾“å‡ºæ—¥å¿—
@before_model
def log_before_model(
        state:AgentState,     #æ•´ä¸ªAgentæ™ºèƒ½ä½“ä¸­çš„çŠ¶æ€è®°å½•
        runtime:Runtime,      #è®°å½•äº†æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
):
    logger.info(f"[log_before_model]å³å°†è°ƒç”¨æ¨¡å‹ï¼Œå¸¦æœ‰{len(state['messages'])}æ¡æ¶ˆæ¯")

                      #ç±»å‹|æœ€æ–°ä¸€æ¡æ¶ˆæ¯å†…å®¹
    logger.debug(f"[log_before_model]{type(state['messages'][-1]).__name__} | {state['messages'][-1].content.strip()}")

    return None

#åŠ¨æ€åˆ‡æ¢æç¤ºè¯
@dynamic_prompt #æ¯æ¬¡åœ¨ç”Ÿæˆæç¤ºè¯ä¹‹å‰è°ƒç”¨æ­¤å‡½æ•°
def report_prompt_switch(request:ModelRequest):
    is_report=request.runtime.context.get("report",False) #è·å–æŒ‡å®švalueï¼ˆFalseä¸ºé»˜è®¤å€¼ï¼‰

    if is_report: #æ˜¯æŠ¥å‘Šç”Ÿæˆåœºæ™¯ï¼Œè¿”å›æŠ¥å‘Šç”Ÿæˆæç¤ºè¯å†…å®¹
        return load_report_prompts()
    return load_system_prompts()