"""
å²—ä½ç”»åƒæ¨¡å— API è·¯ç”±
å¯¹åº” API æ–‡æ¡£ç¬¬ 4 ç« ï¼šJob Profile æ¨¡å—

è·¯ç”±åˆ—è¡¨ï¼š
  POST /api/v1/job/profiles             - 4.1 è·å–å²—ä½ç”»åƒåˆ—è¡¨
  POST /api/v1/job/profile/detail       - 4.2 è·å–å²—ä½è¯¦ç»†ç”»åƒ
  POST /api/v1/job/relation-graph       - 4.3 è·å–å²—ä½å…³è”å›¾è°±
  POST /api/v1/job/ai-generate-profile  - 4.4 AIç”Ÿæˆå²—ä½ç”»åƒ
  POST /api/v1/job/ai-generate-result   - 4.5 è·å–AIç”Ÿæˆç»“æœ
"""

import csv
import json
import os
from flask import Blueprint, request, jsonify, Response
from datetime import datetime
import threading
import json as _json

import csv
from job_profile.job_profile_service import get_job_profile_service, job_profile_conf, _load_profiles_store
from job_profile.job_graph_service import get_job_graph_service
from job_profile.career_path_generator import generate_career_path
from utils.logger_handler import logger
from utils.path_tool import get_abs_path
from utils.config_handler import rag_conf

# å¤§æ¨¡å‹ï¼ˆä¸å…¶å®ƒæ¨¡å—ä¿æŒä¸€è‡´ï¼šé€šä¹‰åƒé—® DashScope / ChatTongyiï¼‰
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# åˆ›å»ºBlueprint
job_bp = Blueprint("job", __name__, url_prefix="/api/v1/job")


# ========== ç»Ÿä¸€å“åº”æ ¼å¼ï¼ˆå¯¹åº”APIæ–‡æ¡£ 0.3ï¼‰==========

def success_response(data, msg="success"):
    return jsonify({"code": 200, "msg": msg, "data": data})


def error_response(code, msg, data=None):
    return jsonify({"code": code, "msg": msg, "data": data}), code


# ============================================================
# Agentï¼šè‡ªç„¶è¯­è¨€éœ€æ±‚è§£æï¼ˆç”¨äºâ€œAIç”Ÿæˆå²—ä½ç”»åƒé¡µé¢â€çš„æ™ºèƒ½å¯¹è¯ç”Ÿæˆï¼‰
# POST /api/v1/job/agent/parse-requirement
# ============================================================
_JOB_AGENT_SYSTEM_PROMPT = """
ä½ æ˜¯å²—ä½ç”»åƒç”ŸæˆåŠ©æ‰‹ï¼Œä»ç”¨æˆ·è¾“å…¥ä¸­æå–ä»¥ä¸‹ä¿¡æ¯å¹¶è¿”å›JSONæ ¼å¼ï¼ˆä»…è¿”å›JSONï¼Œæ— å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
  "å²—ä½åç§°": "",
  "è¡Œä¸šæ–¹å‘": "", // ä»…å¯é€‰ï¼šäº’è”ç½‘/AIã€æ–°èƒ½æºã€é‡‘èã€åŒ»ç–—ã€åˆ¶é€ ä¸šã€å’¨è¯¢
  "ç»éªŒé˜¶æ®µ": ""  // ä»…å¯é€‰ï¼šåº”å±Šç”Ÿã€1-3å¹´ã€3-5å¹´ã€5å¹´ä»¥ä¸Š
}}
""".strip()


def _extract_json_obj(text: str):
    if not text:
        return None
    try:
        return json.loads(text)
    except Exception:
        pass
    # æˆªå–ç¬¬ä¸€ä¸ª { ... } JSON å—
    s = text.find("{")
    e = text.rfind("}")
    if s >= 0 and e > s:
        block = text[s : e + 1]
        try:
            return json.loads(block)
        except Exception:
            return None
    return None


def _fallback_parse_job_requirement(text: str) -> dict:
    """
    å½“å¤§æ¨¡å‹ä¸å¯ç”¨æ—¶çš„æœ¬åœ°å…œåº•è§£æï¼š
    - è¡Œä¸šæ–¹å‘ï¼šæŒ‰å…³é”®è¯ç®€å•æ˜ å°„
    - ç»éªŒé˜¶æ®µï¼šæŒ‰å¸¸è§å¹´ä»½/å…³é”®è¯åŒ¹é…
    - å²—ä½åç§°ï¼šæš‚ç•™ç©ºï¼Œäº¤ç”±å‰ç«¯è¡¥å……
    """
    t = (text or "").strip()
    lower = t.lower()

    # è¡Œä¸šæ–¹å‘ç®€å•è§„åˆ™
    if any(k in t for k in ["äº’è”ç½‘", "AI", "å¤§æ•°æ®", "ç®—æ³•", "å‰ç«¯", "åç«¯", "äº§å“ç»ç†", "æµ‹è¯•", "è¿ç»´"]):
        industry = "äº’è”ç½‘/AI"
    elif any(k in t for k in ["æ–°èƒ½æº", "å…‰ä¼", "é£ç”µ", "å‚¨èƒ½", "é”‚ç”µ"]):
        industry = "æ–°èƒ½æº"
    elif any(k in t for k in ["é“¶è¡Œ", "è¯åˆ¸", "åŸºé‡‘", "ä¿é™©", "é‡‘è"]):
        industry = "é‡‘è"
    elif any(k in t for k in ["åŒ»é™¢", "åŒ»ç–—", "åŒ»è¯", "æŠ¤ç†", "è¯Šæ‰€"]):
        industry = "åŒ»ç–—"
    elif any(k in t for k in ["åˆ¶é€ ", "å·¥å‚", "ç”Ÿäº§çº¿", "æœºæ¢°"]):
        industry = "åˆ¶é€ ä¸š"
    elif any(k in t for k in ["å’¨è¯¢", "é¡¾é—®"]):
        industry = "å’¨è¯¢"
    else:
        industry = ""

    # ç»éªŒé˜¶æ®µç®€å•è§„åˆ™
    if any(k in t for k in ["åº”å±Š", "å®ä¹ ", "æ ¡æ‹›", "æ¯•ä¸šç”Ÿ"]):
        experience = "åº”å±Šç”Ÿ"
    elif "1-3" in lower or "1~3" in lower or "1ï½3" in lower or ("ä¸€å¹´" in t and "ä¸‰å¹´" in t):
        experience = "1-3å¹´"
    elif "3-5" in lower or "3~5" in lower or "3ï½5" in lower or ("ä¸‰å¹´" in t and "äº”å¹´" in t):
        experience = "3-5å¹´"
    elif any(k in t for k in ["5å¹´ä»¥ä¸Š", "äº”å¹´ä»¥ä¸Š", "èµ„æ·±", "é«˜çº§", "ä¸“å®¶", "æ¶æ„å¸ˆ"]):
        experience = "5å¹´ä»¥ä¸Š"
    else:
        experience = ""

    # å²—ä½åç§°ï¼šä¸ºäº†é¿å…è¯¯åˆ¤ï¼Œè¿™é‡Œç•™ç©ºï¼Œè®©å‰ç«¯å¼¹çª—æç¤ºç”¨æˆ·å¡«å†™
    job_name = ""

    return {
        "å²—ä½åç§°": job_name,
        "è¡Œä¸šæ–¹å‘": industry,
        "ç»éªŒé˜¶æ®µ": experience,
    }


@job_bp.route("/agent/parse-requirement", methods=["POST"])
def agent_parse_job_profile_requirement():
    """
    Agentæ ¸å¿ƒé€»è¾‘ - å¤§æ¨¡å‹è§£æï¼š
    è¾“å…¥ï¼š{ "text": "ç”Ÿæˆäº’è”ç½‘/AIè¡Œä¸šåº”å±Šç”Ÿç®—æ³•å·¥ç¨‹å¸ˆç”»åƒ" }
    è¾“å‡ºï¼š{ "å²—ä½åç§°": "...", "è¡Œä¸šæ–¹å‘": "...", "ç»éªŒé˜¶æ®µ": "..." }
    """
    try:
        body = request.get_json(silent=True) or {}
        text = (body.get("text") or body.get("query") or "").strip()
        if not text:
            return error_response(400, "è¯·è¾“å…¥å²—ä½ç”»åƒç”Ÿæˆéœ€æ±‚")

        parsed = None
        try:
            # ä¼˜å…ˆå°è¯•ä½¿ç”¨å¤§æ¨¡å‹è§£æ
            model_name = (rag_conf or {}).get("chat_model_name", "qwen3-max")
            model = ChatTongyi(model=model_name)
            template = PromptTemplate.from_template(
                _JOB_AGENT_SYSTEM_PROMPT
                + "\n\nç”¨æˆ·è¾“å…¥ï¼š{user_text}\n\nåªè¾“å‡ºJSONï¼š"
            )
            chain = template | model | StrOutputParser()
            raw = chain.invoke({"user_text": text})
            raw_text = raw if isinstance(raw, str) else getattr(raw, "content", str(raw))
            parsed = _extract_json_obj(raw_text)
        except Exception as e:
            logger.error("[API] /job/agent/parse-requirement å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è§„åˆ™è§£æ: %s", e, exc_info=True)
            parsed = None

        if not isinstance(parsed, dict):
            parsed = _fallback_parse_job_requirement(text)

        # è§„èŒƒåŒ–/ç™½åå•æ ¡éªŒï¼ˆéæ³•å€¼ç½®ç©ºï¼Œäº¤ç»™å‰ç«¯è¿½é—®è¡¥å……ï¼‰
        out = {
            "å²—ä½åç§°": str(parsed.get("å²—ä½åç§°", "") or "").strip(),
            "è¡Œä¸šæ–¹å‘": str(parsed.get("è¡Œä¸šæ–¹å‘", "") or "").strip(),
            "ç»éªŒé˜¶æ®µ": str(parsed.get("ç»éªŒé˜¶æ®µ", "") or "").strip(),
        }
        allowed_industry = {"äº’è”ç½‘/AI", "æ–°èƒ½æº", "é‡‘è", "åŒ»ç–—", "åˆ¶é€ ä¸š", "å’¨è¯¢"}
        allowed_exp = {"åº”å±Šç”Ÿ", "1-3å¹´", "3-5å¹´", "5å¹´ä»¥ä¸Š"}
        if out["è¡Œä¸šæ–¹å‘"] not in allowed_industry:
            out["è¡Œä¸šæ–¹å‘"] = ""
        if out["ç»éªŒé˜¶æ®µ"] not in allowed_exp:
            out["ç»éªŒé˜¶æ®µ"] = ""

        return success_response(out, msg="æ™ºèƒ½è§£ææˆåŠŸ")
    except Exception as e:
        logger.error(f"[API] /job/agent/parse-requirement å¼‚å¸¸: {e}", exc_info=True)
        # æœ€ç»ˆå…œåº•ï¼šè¿”å›ç©ºç»“æ„ï¼Œç”±å‰ç«¯å¼¹çª—å¼•å¯¼ç”¨æˆ·æ‰‹åŠ¨è¡¥å……
        return success_response(
            {"å²—ä½åç§°": "", "è¡Œä¸šæ–¹å‘": "", "ç»éªŒé˜¶æ®µ": ""},
            msg="æ™ºèƒ½è§£æå¤±è´¥ï¼Œå·²é™çº§ä¸ºæœ¬åœ°è§„åˆ™ï¼Œè¯·æ‰‹åŠ¨è¡¥å……ä¿¡æ¯"
        )


# ========== å¼‚æ­¥ä»»åŠ¡ç®¡ç†ï¼ˆç”¨äºé•¿è€—æ—¶çš„AIç”Ÿæˆä»»åŠ¡ï¼‰==========

_tasks = {}  # task_id -> {status, result, error}
_tasks_lock = threading.Lock()
_TASKS_STORE_DIR = None  # å»¶è¿Ÿè®¡ç®—ï¼Œé¿å…å¾ªç¯ä¾èµ–


def _get_tasks_store_path():
    global _TASKS_STORE_DIR
    if _TASKS_STORE_DIR is None:
        _TASKS_STORE_DIR = get_abs_path("data/ai_tasks")
        os.makedirs(_TASKS_STORE_DIR, exist_ok=True)
    return os.path.join(_TASKS_STORE_DIR, "state.json")


def _persist_tasks():
    """å°†å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€å†™å…¥æ–‡ä»¶ï¼Œä¾¿äºå¤šè¿›ç¨‹/é‡å¯åä»èƒ½æŸ¥åˆ°ç»“æœ"""
    try:
        path = _get_tasks_store_path()
        with _tasks_lock:
            snapshot = {}
            for tid, t in _tasks.items():
                snapshot[tid] = {
                    "status": t.get("status", "pending"),
                    "result": t.get("result"),
                    "error": t.get("error"),
                }
        raw = json.dumps(snapshot, ensure_ascii=False, default=str)
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            f.write(raw)
        if os.path.exists(path):
            os.remove(path)
        os.rename(tmp, path)
    except Exception as e:
        logger.warning(f"[AsyncTask] æŒä¹…åŒ–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")


def _load_persisted_tasks():
    """ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡çŠ¶æ€ï¼Œåˆå¹¶åˆ° _tasksï¼ˆä¸è¦†ç›–å·²æœ‰ keyï¼‰"""
    try:
        path = _get_tasks_store_path()
        if not os.path.exists(path):
            return
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        with _tasks_lock:
            for tid, t in data.items():
                if tid not in _tasks:
                    _tasks[tid] = {
                        "status": t.get("status", "pending"),
                        "result": t.get("result"),
                        "error": t.get("error"),
                    }
    except Exception as e:
        logger.warning(f"[AsyncTask] åŠ è½½æŒä¹…åŒ–ä»»åŠ¡å¤±è´¥: {e}")


def _run_task_async(task_id: str, func, *args, **kwargs):
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œä»»åŠ¡ï¼ŒçŠ¶æ€ä¼šæŒä¹…åŒ–åˆ°æ–‡ä»¶ï¼Œé¿å…å¤šè¿›ç¨‹/é‡å¯å 404"""
    def run():
        try:
            _tasks[task_id]["status"] = "processing"
            _persist_tasks()
            result = func(*args, **kwargs)
            _tasks[task_id]["status"] = "completed"
            _tasks[task_id]["result"] = result
            _persist_tasks()
        except Exception as e:
            logger.error(f"[AsyncTask] ä»»åŠ¡{task_id}å¤±è´¥: {e}", exc_info=True)
            _tasks[task_id]["status"] = "failed"
            _tasks[task_id]["error"] = str(e)
            _persist_tasks()

    _tasks[task_id] = {"status": "pending", "result": None, "error": None}
    _persist_tasks()
    thread = threading.Thread(target=run, daemon=True)
    thread.start()


# ============================================================
# 4.1 è·å–å²—ä½ç”»åƒåˆ—è¡¨
# POST /api/v1/job/profiles  æˆ–  GET /api/v1/job/profiles?page=1&size=12&keyword=xxx&industry=xxx&level=xxx
# ============================================================
def _get_profiles_params():
    """ä» GET æŸ¥è¯¢ä¸²æˆ– POST body è¯»å– page, size, keyword, industry, level"""
    if request.method == "GET":
        page = request.args.get("page", "1")
        size = request.args.get("size", "20")
        keyword = request.args.get("keyword", "").strip() or None
        industry = request.args.get("industry", "").strip() or None
        level = request.args.get("level", "").strip() or None
    else:
        body = request.get_json(silent=True) or {}
        page = body.get("page", 1)
        size = body.get("size", 20)
        keyword = body.get("keyword") or None
        industry = body.get("industry") or None
        level = body.get("level") or None
    page = int(page) if page else 1
    size = int(size) if size else 20
    return page, size, keyword, industry, level


@job_bp.route("/profiles", methods=["GET", "POST"])
def get_job_profiles():
    """
    è·å–å²—ä½ç”»åƒåˆ—è¡¨ã€‚GET ç”¨æŸ¥è¯¢å‚æ•°ï¼ŒPOST ç”¨è¯·æ±‚ä½“ã€‚
    å‚æ•°ï¼špage, size, keyword, industry, level
    """
    try:
        page, size, keyword, industry, level = _get_profiles_params()
        if page < 1 or size < 1 or size > 100:
            return error_response(400, "åˆ†é¡µå‚æ•°é”™è¯¯ï¼špage>=1, 1<=size<=100")

        service = get_job_profile_service()
        result = service.get_profile_list(page=page, size=size,
                                          keyword=keyword, industry=industry, level=level)
        return success_response(result)

    except Exception as e:
        logger.error(f"[API] /job/profiles å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# çœŸå®æ‹›è˜æ•°æ®ï¼šå…ˆæŸ¥ CSVï¼ˆå‰4å­—æ¨¡ç³ŠåŒ¹é…ï¼‰ï¼Œæ— ç»“æœåˆ™ AI ç”Ÿæˆï¼Œè¿”å›ä¸åŠ  isAIGenerated
# GET /api/v1/job/real-data?jobName=ç®—æ³•å·¥ç¨‹å¸ˆ&size=5
# ============================================================

def _search_csv(job_name, size):
    """ä» CSV æŒ‰å²—ä½åå‰ 4 å­—æ¨¡ç³ŠåŒ¹é…ï¼Œæœ€å¤šè¿”å› size æ¡ã€‚"""
    csv_path = get_abs_path("data/æ±‚èŒå²—ä½ä¿¡æ¯æ•°æ®.csv")
    if not job_name or not os.path.exists(csv_path):
        return []
    keyword = (job_name[:4] if len(job_name) >= 4 else job_name).strip()
    if not keyword:
        return []
    results = []
    try:
        with open(csv_path, encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                title = (row.get("èŒä½åç§°") or "").strip()
                if keyword in title:
                    desc = (row.get("èŒä½æè¿°") or "").strip()
                    intro = (row.get("å…¬å¸ç®€ä»‹") or "").strip()
                    results.append({
                        "jobTitle": title,
                        "company": row.get("å…¬å¸å…¨ç§°", ""),
                        "salary": row.get("è–ªèµ„èŒƒå›´", ""),
                        "address": row.get("å·¥ä½œåœ°å€", ""),
                        "industry": row.get("æ‰€å±è¡Œä¸š", ""),
                        "scale": row.get("äººå‘˜è§„æ¨¡", ""),
                        "companyType": row.get("ä¼ä¸šæ€§è´¨", ""),
                        "description": (desc[:200] + "â€¦") if len(desc) > 200 else desc,
                        "companyIntro": (intro[:150] + "â€¦") if len(intro) > 150 else intro,
                    })
                    if len(results) >= size:
                        break
    except Exception as e:
        logger.warning(f"[API] real-data è¯»å– CSV å¤±è´¥: {e}", exc_info=True)
    return results


@job_bp.route("/real-data", methods=["GET"])
def get_real_data():
    job_name = (request.args.get("jobName") or "").strip()
    try:
        size = int(request.args.get("size", 3))
        size = max(1, min(size, 20))
    except (TypeError, ValueError):
        size = 3

    results = _search_csv(job_name, size)

    if not results:
        try:
            from dashscope import Generation
            prompt = f"""ä¸ºå²—ä½ã€{job_name}ã€‘ç”Ÿæˆ{size}æ¡æ‹›è˜ä¿¡æ¯ï¼Œé£æ ¼çœŸå®è‡ªç„¶ã€‚
åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š
{{"jobs":[
  {{
    "jobTitle":"{job_name}",
    "company":"å…¬å¸å",
    "salary":"è–ªèµ„èŒƒå›´",
    "address":"åŸå¸‚Â·åŒºÂ·è¡—é“",
    "industry":"è¡Œä¸š",
    "scale":"äººå‘˜è§„æ¨¡",
    "companyType":"ä¼ä¸šæ€§è´¨",
    "description":"èŒä½æè¿°120å­—",
    "companyIntro":"å…¬å¸ç®€ä»‹60å­—"
  }}
]}}
è¯·æŒ‰ä¸Šè¿°æ ¼å¼ç”Ÿæˆ{size}æ¡ï¼Œæ¯æ¡å­—æ®µå®Œæ•´ã€‚"""
            response = Generation.call(
                model="qwen3-max",
                messages=[{"role": "user", "content": prompt}],
                result_format="message",
            )
            content = (response.output.choices[0].message.content or "").strip()
            content = content.replace("```json", "").replace("```", "").strip()
            data = json.loads(content)
            results = data.get("jobs", [])[:size]
        except Exception as e:
            logger.error(f"[API] real-data AI ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            results = []

    return success_response(results)


# ============================================================
# å²—ä½ç”»åƒæµå¼ç”Ÿæˆï¼ˆSSEï¼‰
# POST /api/v1/job/generate-profile-stream
# ============================================================
def _stream_job_profile_generate(job_name: str, job_description: str):
    """Generator: yield SSE events (data: {...}\n\n). ä½¿ç”¨ dashscope Generation æµå¼è°ƒç”¨ã€‚"""
    prompt = f"""ä½ æ˜¯èŒä¸šè§„åˆ’ä¸“å®¶ã€‚æ ¹æ®å²—ä½"{job_name}"å’Œæè¿°"{job_description}"ç”Ÿæˆå²—ä½ç”»åƒã€‚
ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸åŠ ä»»ä½•å¤šä½™å†…å®¹ï¼Œä¸åŠ markdownä»£ç å—ï¼š
{{
  "salary": "è–ªèµ„èŒƒå›´",
  "location": "ä¸»è¦åŸå¸‚",
  "company_size": "å…¬å¸è§„æ¨¡",
  "demand_score": 88,
  "trend": "ä¸Šå‡",
  "experience": "1-3å¹´",
  "education": "æœ¬ç§‘åŠä»¥ä¸Š",
  "competition": "æ¨èç«èµ›ç»å†",
  "english": "è‹±è¯­è¦æ±‚æè¿°",
  "internship": "æ¨è3ä¸ªæœˆä»¥ä¸Šç›¸å…³å®ä¹ ç»å†ï¼Œå¤§å‚æˆ–AIå®éªŒå®¤ä¼˜å…ˆ",
  "description": "é’ˆå¯¹è¯¥å²—ä½çš„èŒè´£ã€è¦æ±‚ä¸å·¥ä½œå†…å®¹çš„è¯¦ç»†æè¿°ï¼Œçº¦150-200å­—",
  "skills_core": ["æ ¸å¿ƒæŠ€èƒ½1","æ ¸å¿ƒæŠ€èƒ½2","æ ¸å¿ƒæŠ€èƒ½3","æ ¸å¿ƒæŠ€èƒ½4","æ ¸å¿ƒæŠ€èƒ½5"],
  "skills_advanced": ["è¿›é˜¶æŠ€èƒ½1","è¿›é˜¶æŠ€èƒ½2","è¿›é˜¶æŠ€èƒ½3"],
  "skills_plus": ["åŠ åˆ†æŠ€èƒ½1","åŠ åˆ†æŠ€èƒ½2"],
  "abilities": [
    {{"icon":"ğŸ§ ","name":"å­¦ä¹ èƒ½åŠ›","level":"é«˜è¦æ±‚","level_type":"high","desc":"é’ˆå¯¹{job_name}çš„å­¦ä¹ èƒ½åŠ›è¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—ï¼Œè¯´æ˜éœ€è¦æŒæ¡å“ªäº›çŸ¥è¯†ä½“ç³»ã€å¦‚ä½•æŒç»­å­¦ä¹ ","keywords":["å…³é”®è¯1","å…³é”®è¯2"]}},
    {{"icon":"ğŸ’¡","name":"åˆ›æ–°èƒ½åŠ›","level":"é«˜è¦æ±‚","level_type":"high","desc":"é’ˆå¯¹{job_name}çš„åˆ›æ–°èƒ½åŠ›è¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—","keywords":["å…³é”®è¯1"]}},
    {{"icon":"ğŸ”¥","name":"æŠ—å‹èƒ½åŠ›","level":"ä¸­ç­‰è¦æ±‚","level_type":"medium","desc":"é’ˆå¯¹{job_name}çš„æŠ—å‹èƒ½åŠ›è¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—","keywords":["å…³é”®è¯1"]}},
    {{"icon":"ğŸ’¬","name":"æ²Ÿé€šèƒ½åŠ›","level":"ä¸­ç­‰è¦æ±‚","level_type":"medium","desc":"é’ˆå¯¹{job_name}çš„æ²Ÿé€šèƒ½åŠ›è¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—","keywords":["å…³é”®è¯1"]}},
    {{"icon":"ğŸ¤","name":"å›¢é˜Ÿåä½œ","level":"ä¸­ç­‰è¦æ±‚","level_type":"medium","desc":"é’ˆå¯¹{job_name}çš„å›¢é˜Ÿåä½œè¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—","keywords":["å…³é”®è¯1"]}},
    {{"icon":"ğŸ¢","name":"å®ä¹ èƒ½åŠ›","level":"åŸºç¡€è¦æ±‚","level_type":"base","desc":"é’ˆå¯¹{job_name}çš„å®ä¹ èƒ½åŠ›è¦æ±‚è¯¦ç»†æè¿°ï¼Œçº¦100å­—ï¼ŒåŒ…å«æ¨èå®ä¹ æ—¶é•¿å’Œæ–¹å‘","keywords":["å…³é”®è¯1","å…³é”®è¯2"]}}
  ],
  "certs": [
    {{"icon":"ğŸ…","name":"è¯ä¹¦åç§°","desc":"è¯ä¹¦è¯´æ˜å’Œè¦æ±‚åˆ†æ•°","type":"å¿…é¡»","type_code":"must"}},
    {{"icon":"ğŸ“œ","name":"è¯ä¹¦åç§°","desc":"è¯ä¹¦è¯´æ˜","type":"åŠ åˆ†é¡¹","type_code":"plus"}},
    {{"icon":"ğŸŒ","name":"è¯ä¹¦åç§°","desc":"è¯ä¹¦è¯´æ˜","type":"æ¨è","type_code":"opt"}}
  ],
  "intern_directions": [
    {{"type":"æ–¹å‘ç±»å‹","icon":"ğŸ¢","role":"æ¨èå®ä¹ å²—ä½åç§°","companies":["å…¬å¸1","å…¬å¸2","å…¬å¸3","å…¬å¸4"]}},
    {{"type":"æ–¹å‘ç±»å‹","icon":"ğŸ”¬","role":"æ¨èå®ä¹ å²—ä½åç§°","companies":["å…¬å¸1","å…¬å¸2","å…¬å¸3"]}}
  ]
}}
æ‰€æœ‰å†…å®¹å¿…é¡»é’ˆå¯¹{job_name}ä¸ªæ€§åŒ–ç”Ÿæˆï¼Œabilitieså¿…é¡»åŒ…å«ä»¥ä¸Š6é¡¹ä¸”é¡ºåºä¸å˜ï¼Œlevel_typeåªèƒ½æ˜¯high/medium/baseï¼Œtype_codeåªèƒ½æ˜¯must/plus/optã€‚"""

    try:
        from dashscope import Generation
        response = Generation.call(
            model="qwen3-max",
            messages=[{"role": "user", "content": prompt}],
            result_format="message",
            stream=True,
        )
        for chunk in response:
            content = ""
            if getattr(chunk, "output", None) and getattr(chunk.output, "choices", None):
                choices = chunk.output.choices
                if choices and len(choices) > 0:
                    msg = getattr(choices[0], "message", None)
                    if msg is not None:
                        content = getattr(msg, "content", None) or ""
            if content:
                yield f"data: {_json.dumps({'text': content}, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"
    except Exception as e:
        logger.error(f"[API] generate-profile-stream å¼‚å¸¸: {e}", exc_info=True)
        yield f"data: {_json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"


@job_bp.route("/generate-profile-stream", methods=["POST"])
def generate_profile_stream():
    """
    å²—ä½ç”»åƒæµå¼ç”Ÿæˆï¼Œè¿”å› SSEã€‚
    è¯·æ±‚ä½“ï¼š{ job_name, job_description }ï¼Œjob_description å¯é€‰ã€‚
    """
    try:
        body = request.get_json(silent=True) or {}
        job_name = (body.get("job_name") or "").strip() or ""
        job_description = (body.get("job_description") or "").strip() or ""

        def stream_generator():
            for chunk in _stream_job_profile_generate(job_name, job_description):
                yield chunk

        return Response(
            stream_generator(),
            mimetype="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "X-Accel-Buffering": "no",
                "Connection": "keep-alive",
            },
        )
    except Exception as e:
        logger.error(f"[API] /job/generate-profile-stream å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# è·å–è¡Œä¸šåˆ—è¡¨ï¼ˆä¾›å‰ç«¯ç­›é€‰ä¸‹æ‹‰åŠ¨æ€åŠ è½½ï¼‰
# GET /api/v1/job/industries
# ============================================================
@job_bp.route("/industries", methods=["GET"])
def get_job_industries():
    """è¿”å›æ‰€æœ‰å²—ä½ä¸­çš„å»é‡è¡Œä¸šåˆ—è¡¨"""
    try:
        service = get_job_profile_service()
        industries = service.get_industries()
        return success_response({"industries": industries})
    except Exception as e:
        logger.error(f"[API] /job/industries å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.2 è·å–å²—ä½è¯¦ç»†ç”»åƒ
# POST /api/v1/job/profile/detail
# ============================================================
def _minimal_profile_from_target_jobs(job_id_or_name):
    """å½“ store ä¸­æ— è¯¥å²—ä½æ—¶ï¼Œç”¨ target_jobs é…ç½®å…œåº•ï¼Œé¿å…ã€Œå²—ä½ç”»åƒã€æŒ‰é’® 404ã€‚ä¸çœŸå®æ•°æ®æ¥å£äº’ç‹¬ç«‹ã€‚"""
    target = job_profile_conf.get("target_jobs", [])
    job_id_or_name = (job_id_or_name or "").strip()
    if not job_id_or_name:
        return None
    for j in target:
        if j.get("job_id") == job_id_or_name or (j.get("name") or "").strip() == job_id_or_name:
            name = j.get("name", "")
            level_map = {1: "å®ä¹ /åŠ©ç†", 2: "åˆçº§", 3: "ä¸­çº§", 4: "é«˜çº§", 5: "æ¶æ„å¸ˆ", 6: "æ€»ç›‘"}
            level = level_map.get(j.get("layer_level"), "ä¸­çº§")
            return {
                "job_id": j.get("job_id", ""),
                "job_name": name,
                "basic_info": {
                    "industry": j.get("category", "äº’è”ç½‘/AI"),
                    "level": level,
                    "level_range": [level],
                    "avg_salary": "é¢è®®",
                    "work_locations": [],
                    "company_scales": [],
                    "description": f"è¯¥å²—ä½æš‚æ— è¯¦ç»†ç”»åƒï¼Œå¯åœ¨ã€ŒAIç”Ÿæˆã€é¡µè¾“å…¥ã€Œ{name}ã€ç”Ÿæˆå®Œæ•´ç”»åƒã€‚",
                },
                "market_analysis": {"demand_score": 80, "growth_trend": "ä¸Šå‡"},
                "description": f"æ¥è‡ªå²—ä½é…ç½®ï¼š{name}ï¼ˆ{j.get('category', '')}ï¼‰ã€‚ç‚¹å‡» AI ç”Ÿæˆå¯è·å–å®Œæ•´ç”»åƒã€‚",
            }
    for j in target:
        if job_id_or_name in (j.get("name") or ""):
            return _minimal_profile_from_target_jobs(j.get("name"))
    return None


@job_bp.route("/profile/detail", methods=["POST"])
def get_job_profile_detail():
    """
    è·å–å•ä¸ªå²—ä½çš„å®Œæ•´è¯¦ç»†ç”»åƒ
    è¯·æ±‚ä½“ï¼š{ job_id } æˆ– { job_name }
    """
    try:
        body = request.get_json(silent=True) or {}
        job_id = body.get("job_id")
        job_name = body.get("job_name")

        if not job_id and not job_name:
            return error_response(400, "è¯·æä¾› job_id æˆ– job_name å‚æ•°")

        service = get_job_profile_service()
        profile = None

        if job_id:
            profile = service.get_profile_detail(job_id)
        if not profile and job_name:
            profile = service.get_profile_by_name(job_name)
        if not profile and job_id:
            profile = service.get_profile_by_name(job_id)

        # è‹¥ä»æ— ç”»åƒï¼ˆå¦‚åˆ—è¡¨æ¥è‡ªç²¾é€‰é…ç½® job_001 ä½† store æ¥è‡ª CSVï¼‰ï¼Œç”¨ target_jobs å…œåº•ï¼Œé¿å… 404
        if not profile:
            profile = _minimal_profile_from_target_jobs(job_id or job_name)

        if not profile:
            return error_response(404, f"æœªæ‰¾åˆ°å²—ä½ç”»åƒï¼š{job_id or job_name}")

        return success_response(profile)

    except Exception as e:
        logger.error(f"[API] /job/profile/detail å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.3 è·å–å²—ä½å…³è”å›¾è°±
# POST /api/v1/job/relation-graph
# ============================================================
def _empty_graph_data(center_job_id=None, message="æš‚æ— æ•°æ®"):
    """è¿”å›å‰ç«¯æœŸæœ›çš„ç©ºå›¾è°±ç»“æ„ï¼Œé¿å…ç©ºå“åº”æˆ–ç¼ºå¤±å­—æ®µå¯¼è‡´åŠ è½½å¤±è´¥"""
    return {
        "center_job": {"job_id": center_job_id or "", "job_name": "", "level": 0, "salary_range": "", "avg_salary": "", "demand_score": None},
        "vertical_graph": {"nodes": [], "edges": [], "track_name": "", "message": message},
        "transfer_graph": {"nodes": [], "edges": [], "message": message},
        "career_path": {"promotion_path": []},
    }


def _resolve_job_id_from_name(job_name):
    """æ ¹æ®å²—ä½åç§°è§£æä¸º target_jobs çš„ job_idï¼Œç”¨äºæ™‹å‡è·¯å¾„æŸ¥åº“ã€‚"""
    job_name = (job_name or "").strip()
    if not job_name:
        return None
    import re
    name_core = re.sub(r"\s*[ï¼ˆ(].*?[)ï¼‰]\s*", "", job_name).strip() or job_name
    target_jobs = job_profile_conf.get("target_jobs", [])
    for t in target_jobs:
        tid = t.get("job_id", "")
        tname = (t.get("name") or "").strip()
        if not tname:
            continue
        if name_core in tname or tname in name_core:
            return tid
    return None


def _resolve_job_id_for_graph(job_id):
    """
    å°†åˆ—è¡¨/CSV çš„ job_idï¼ˆå¦‚ A174435ï¼‰è§£æä¸ºå›¾è°±ä½¿ç”¨çš„ target_jobs job_idï¼ˆå¦‚ job_011ï¼‰ï¼Œ
    ä»¥ä¾¿ä» DB æˆ– graph.json ç§’çº§è¿”å›ï¼Œé¿å…èµ°å®æ—¶ LLM å¯¼è‡´è¯·æ±‚æŒ‚èµ·ã€å“åº”ä¸ºç©ºã€‚
    è¿”å› (resolved_id, display_name)ï¼šresolved_id ç”¨äºæŸ¥ DB/å›¾ï¼Œdisplay_name ç”¨äº center_job å±•ç¤ºã€‚
    """
    job_id = (job_id or "").strip()
    if not job_id:
        return None, ""
    target_jobs = job_profile_conf.get("target_jobs", [])
    job_index = {j["job_id"]: j for j in target_jobs}
    if job_id in job_index:
        return job_id, (job_index[job_id].get("name") or job_id)

    # ä» profiles_store å–å²—ä½åç§°ï¼Œå†æŒ‰åç§°åŒ¹é… target_jobs
    profiles = _load_profiles_store()
    job_name = ""
    if job_id in profiles:
        job_name = (profiles[job_id].get("job_name") or "").strip()
    if not job_name:
        job_name = job_id
    # å»æ‰æ‹¬å·åç¼€ä¾¿äºåŒ¹é…ï¼Œå¦‚ "ç®—æ³•å·¥ç¨‹å¸ˆ(A174435)" -> "ç®—æ³•å·¥ç¨‹å¸ˆ"
    import re
    name_core = re.sub(r"\s*[ï¼ˆ(].*?[)ï¼‰]\s*", "", job_name).strip() or job_name
    for t in target_jobs:
        tid = t.get("job_id", "")
        tname = (t.get("name") or "").strip()
        if not tname:
            continue
        if name_core in tname or tname in name_core:
            return tid, job_name or tname
    return job_id, job_name or job_id


def _build_graph_data_from_json(resolved_id, graph_type, display_name, job_index):
    """ä» data/job_profiles/graph.json æ„å»º API æ‰€éœ€ç»“æ„ï¼Œç§’çº§è¿”å›ï¼Œé¿å…è¯·æ±‚æŒ‚èµ·ã€‚"""
    graph_path = get_abs_path(job_profile_conf.get("job_graph_store", "data/job_profiles/graph.json"))
    if not graph_path or not os.path.isfile(graph_path):
        return None
    try:
        with open(graph_path, "r", encoding="utf-8") as f:
            graph_file = json.load(f)
    except Exception as e:
        logger.warning(f"[API] è¯»å– graph.json å¤±è´¥: {e}")
        return None
    nodes_by_id = {n["job_id"]: n for n in graph_file.get("transfer_graph", {}).get("nodes", [])}
    all_edges = graph_file.get("transfer_graph", {}).get("edges", [])
    center_node = nodes_by_id.get(resolved_id, {})
    center_name = display_name or center_node.get("job_name", resolved_id)
    center_job = {
        "job_id": resolved_id,
        "job_name": center_name,
        "level": center_node.get("layer_level", job_index.get(resolved_id, {}).get("layer_level", 0)),
        "salary_range": "",
        "avg_salary": "",
        "demand_score": None,
    }
    result = {"center_job": center_job}

    # å‚ç›´å›¾è°±ï¼šä» vertical_graphs ä¸­æ‰¾åˆ°åŒ…å« resolved_id çš„ track
    vertical_graphs = graph_file.get("vertical_graphs", [])
    v_nodes, v_edges, track_name = [], [], ""
    for track in vertical_graphs:
        nodes_list = track.get("nodes", [])
        ids_in_track = [n["job_id"] for n in nodes_list]
        if resolved_id in ids_in_track and graph_type in ("vertical", "all"):
            v_nodes = [{"job_id": n["job_id"], "job_name": n.get("job_name", n["job_id"]), "level": n.get("layer_level", 0), "category": n.get("category", ""), "salary_range": "", "description": ""} for n in nodes_list]
            v_edges = [{"from": e.get("from"), "to": e.get("to"), "years": e.get("years", "2-3å¹´"), "requirements": e.get("requirements", [])} for e in track.get("edges", [])]
            track_name = track.get("career_track", "æ™‹å‡è·¯å¾„")
            break
    result["vertical_graph"] = {"nodes": v_nodes, "edges": v_edges, "track_name": track_name, "message": "" if v_nodes else "æš‚æ— å‚ç›´è·¯å¾„"}

    # è½¬å²—å›¾è°±ï¼šedges ä¸­ from == resolved_id çš„è¾¹åŠå…¶ to èŠ‚ç‚¹
    out_edges = [e for e in all_edges if e.get("from") == resolved_id]
    to_ids = list({e.get("to") for e in out_edges if e.get("to")})
    transfer_nodes = [nodes_by_id.get(jid, {"job_id": jid, "job_name": jid}) for jid in to_ids]
    transfer_nodes = [{"job_id": n["job_id"], "job_name": n.get("job_name", n["job_id"]), "level": n.get("layer_level", 0), "category": n.get("category", ""), "salary_range": "", "description": ""} for n in transfer_nodes]
    transfer_edges = [
        {"from": e["from"], "to": e["to"], "relevance_score": e.get("relevance_score", 70), "match_score": e.get("relevance_score", 70), "difficulty": e.get("difficulty", "ä¸­"), "time": e.get("time", "6-12ä¸ªæœˆ"), "skills_gap": e.get("skills_gap", [])}
        for e in out_edges[:15]
    ]
    result["transfer_graph"] = {"nodes": transfer_nodes, "edges": transfer_edges, "message": ""}
    result["career_path"] = {"promotion_path": []}
    return result


@job_bp.route("/relation-graph", methods=["POST"])
def get_job_relation_graph():
    """
    è·å–å²—ä½é—´çš„è¡€ç¼˜å…³ç³»å’Œè½¬æ¢è·¯å¾„
    è¯·æ±‚ä½“ï¼š{ job_id, graph_type }
    graph_type: vertical / transfer / all
    åˆ—è¡¨ job_idï¼ˆå¦‚ A174435ï¼‰ä¼šè§£æä¸º target_jobs idï¼ˆå¦‚ job_011ï¼‰ï¼Œä¼˜å…ˆ DB / graph.json ç§’çº§è¿”å›ï¼Œé¿å…å“åº”æŒ‚èµ·ä¸ºç©ºã€‚
    """
    body = request.get_json(silent=True) or {}
    job_id = (body.get("job_id") or "").strip()
    graph_type = body.get("graph_type", "all")
    logger.info(f"[API] relation-graph æ¥å£è¢«è°ƒç”¨, å‚æ•°: job_id={job_id!r}, graph_type={graph_type!r}")

    try:
        if not job_id:
            return error_response(400, "è¯·æä¾› job_id å‚æ•°")

        if graph_type not in ("vertical", "transfer", "all"):
            return error_response(400, "graph_type å‚æ•°é”™è¯¯ï¼Œæ”¯æŒ: vertical/transfer/all")

        resolved_id, display_name = _resolve_job_id_for_graph(job_id)
        if not resolved_id:
            return error_response(400, "æ— æ³•è§£æå²—ä½ ID")
        job_index = {j["job_id"]: j for j in job_profile_conf.get("target_jobs", [])}

        # 1) ä¼˜å…ˆä» job_relations è¡¨è¯»å–
        try:
            from job_profile.job_relations_db import init_db, build_graph_data_from_db
            init_db()
            db_data = build_graph_data_from_db(resolved_id, graph_type, job_index)
            if db_data is not None:
                for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                    if key not in db_data:
                        db_data[key] = _empty_graph_data(resolved_id)[key]
                if display_name and db_data.get("center_job"):
                    db_data["center_job"]["job_name"] = display_name
                return success_response(db_data)
        except Exception as e:
            logger.warning(f"[API] relation-graph ä» DB è¯»å–å¤±è´¥: {e}")

        # 2) ä» graph.json ç§’çº§è¿”å›ï¼Œé¿å…å®æ—¶ LLM å¯¼è‡´æŒ‚èµ·ã€å“åº”ä¸ºç©º
        json_data = _build_graph_data_from_json(resolved_id, graph_type, display_name, job_index)
        if json_data is not None:
            for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                if key not in json_data:
                    json_data[key] = _empty_graph_data(resolved_id)[key]
            return success_response(json_data)

        # 3) å›é€€å®æ—¶æ„å»ºï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
        graph_service = get_job_graph_service()
        graph_data = graph_service.get_job_graph(resolved_id, graph_type)

        if not isinstance(graph_data, dict):
            graph_data = _empty_graph_data(resolved_id, "æ•°æ®æ ¼å¼å¼‚å¸¸")
        else:
            for key in ("center_job", "vertical_graph", "transfer_graph", "career_path"):
                if key not in graph_data:
                    graph_data[key] = _empty_graph_data(resolved_id)[key]
        if display_name and graph_data.get("center_job"):
            graph_data["center_job"]["job_name"] = display_name
        return success_response(graph_data)

    except ValueError as e:
        logger.warning(f"[API] /job/relation-graph ä¸šåŠ¡é”™è¯¯: {e}")
        return error_response(404, str(e))
    except Exception as e:
        logger.error(f"[API] /job/relation-graph å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.3.1 è·å–å²—ä½æ™‹å‡è·¯å¾„ï¼ˆä¼˜å…ˆ DB job_promotion_pathï¼Œå¦åˆ™ LLM ç”Ÿæˆï¼‰
# GET /api/v1/job/career-path?jobName=xxxï¼ˆå‰ç«¯æ™‹å‡è·¯å¾„å¡ç‰‡å¯æ¥æ­¤ï¼›é˜Ÿå‹ä¾§ jobId æ¢å²—æ•°æ®å¯å¦æ¥ï¼‰
# ============================================================
@job_bp.route("/career-path", methods=["GET"])
def get_job_career_path():
    """
    æ ¹æ®å²—ä½åç§°æˆ– jobId è¿”å› 4 ä¸ªæ™‹å‡é˜¶æ®µï¼Œä¾›å‰ç«¯æ™‹å‡è·¯å¾„å¡ç‰‡ä½¿ç”¨ã€‚
    æ”¯æŒ jobName æˆ– jobIdï¼šjobId æ—¶ä» profiles_store è§£æå²—ä½åç§°ã€‚
    ä¼˜å…ˆä» job_promotion_path è¡¨è¯»å–ï¼Œç¡®ä¿æœ‰é˜¶æ®µåã€å¹´é™ã€è–ªèµ„ï¼›æ— åˆ™å›é€€ LLMã€‚
    è¿”å› data.path: [ { stage, icon, salary, skills, desc, years }, ... ]
    """
    try:
        job_name = (request.args.get("jobName") or "").strip()
        job_id = (request.args.get("jobId") or "").strip()
        if not job_name and job_id:
            profiles = _load_profiles_store()
            profile = profiles.get(job_id) if isinstance(profiles, dict) else None
            if profile and isinstance(profile, dict):
                job_name = (profile.get("job_name") or profile.get("name") or "").strip()
            if not job_name:
                resolved_id, display_name = _resolve_job_id_for_graph(job_id)
                if display_name:
                    job_name = display_name
        if not job_name:
            return error_response(400, "è¯·æä¾› jobName æˆ– jobId å‚æ•°")

        path = []
        job_id = _resolve_job_id_from_name(job_name)
        if job_id:
            try:
                from job_profile.job_relations_db import init_db, get_promotion_path_by_job_id
                init_db()
                rows = get_promotion_path_by_job_id(job_id)
                if rows and len(rows) >= 4:
                    default_icons = ["ğŸŒ±", "ğŸŒ¿", "ğŸŒ³", "ğŸ†"]
                    for i, r in enumerate(rows[:4]):
                        skills = r.get("skills")
                        if isinstance(skills, str) and skills.strip():
                            try:
                                skills = json.loads(skills)
                            except Exception:
                                skills = [s.strip() for s in skills.split(",") if s.strip()]
                        else:
                            skills = []
                        path.append({
                            "stage": r.get("stage_name") or r.get("role_title") or "",
                            "icon": (r.get("icon") or "").strip() or default_icons[i],
                            "salary": r.get("salary_range") or "",
                            "skills": skills if isinstance(skills, list) else [],
                            "desc": "",
                            "years": r.get("years_range") or "",
                        })
            except Exception as e:
                logger.warning(f"[API] career-path ä» DB è¯»å–å¤±è´¥ï¼Œå›é€€ LLM: {e}")

        if not path:
            raw = generate_career_path(job_name)
            for i, s in enumerate(raw[:4]):
                path.append({
                    "stage": s.get("name", ""),
                    "icon": s.get("icon", "ğŸŒ±"),
                    "salary": s.get("salary_increase", ""),
                    "skills": s.get("key_skills") or [],
                    "desc": s.get("desc", ""),
                    "years": s.get("time_range", ""),
                })

        return success_response({"path": path})
    except Exception as e:
        logger.error(f"[API] /job/career-path å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.4 AIç”Ÿæˆå²—ä½ç”»åƒï¼ˆå¼‚æ­¥è§¦å‘ï¼‰
# POST /api/v1/job/ai-generate-profile
# ============================================================

def _resolve_job_config(job_name: str, target_jobs: list) -> dict:
    """
    å°†ç”¨æˆ·è¾“å…¥çš„å²—ä½åç§°è§£æä¸ºå¯ç”¨çš„å²—ä½é…ç½®ï¼Œæ”¯æŒä»»æ„å²—ä½åï¼š
    1. ç²¾ç¡®åŒ¹é…é…ç½®ä¸­çš„ name
    2. æ¨¡ç³ŠåŒ¹é…ï¼šé…ç½® name æˆ– csv_keywords åŒ…å«ç”¨æˆ·è¾“å…¥ã€æˆ–ç”¨æˆ·è¾“å…¥åŒ…å«é…ç½®å…³é”®è¯
    3. å…œåº•ï¼šæŒ‰å¸¸è§å…³é”®è¯é€‰æœ€ç›¸è¿‘æ¨¡æ¿ï¼ˆå¦‚ã€Œç®—æ³•ã€â†’ æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆï¼‰
    """
    if not job_name or not target_jobs:
        return None
    job_name = (job_name or "").strip()
    # 1) ç²¾ç¡®åŒ¹é…
    exact = next((j for j in target_jobs if j.get("name") == job_name), None)
    if exact:
        return dict(exact)

    # 2) æ¨¡ç³ŠåŒ¹é…ï¼šç”¨æˆ·è¾“å…¥åŒ…å«é…ç½®åä¸­çš„æŸæ®µï¼Œæˆ–é…ç½®ååŒ…å«ç”¨æˆ·è¾“å…¥
    for j in target_jobs:
        name = (j.get("name") or "")
        if job_name in name or name in job_name:
            cfg = dict(j)
            cfg["name"] = job_name
            return cfg
    # é…ç½®çš„ csv_keywords ä¸­ä»»æ„å…³é”®è¯å‡ºç°åœ¨ç”¨æˆ·è¾“å…¥é‡Œ
    for j in target_jobs:
        keywords = j.get("csv_keywords") or []
        if any(kw and str(kw).lower() in job_name.lower() for kw in keywords):
            cfg = dict(j)
            cfg["name"] = job_name
            return cfg
    # é…ç½® name çš„æŸéƒ¨åˆ†ï¼ˆå¦‚ "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ" çš„ "ç®—æ³•å·¥ç¨‹å¸ˆ"ï¼‰åœ¨ç”¨æˆ·è¾“å…¥é‡Œ
    for j in target_jobs:
        name = (j.get("name") or "")
        for part in name.replace("ã€", "/").split("/"):
            part = part.strip()
            if part and part in job_name:
                cfg = dict(j)
                cfg["name"] = job_name
                return cfg

    # 3) å…œåº•ï¼šæŒ‰å…³é”®è¯é€‰æœ€ç›¸è¿‘æ¨¡æ¿
    fallback_map = [
        ("ç®—æ³•", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("æœºå™¨å­¦ä¹ ", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("å¤§æ¨¡å‹", "å¤§æ¨¡å‹/AIGCåº”ç”¨å·¥ç¨‹å¸ˆ"),
        ("ç®—æ³•å·¥ç¨‹å¸ˆ", "æœºå™¨å­¦ä¹ /ç®—æ³•å·¥ç¨‹å¸ˆ"),
        ("å¼€å‘", "Javaåç«¯å¼€å‘å·¥ç¨‹å¸ˆ"),
        ("å‰ç«¯", "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"),
        ("æµ‹è¯•", "è½¯ä»¶æµ‹è¯•å·¥ç¨‹å¸ˆ"),
        ("äº§å“", "äº§å“ç»ç†"),
        ("æ•°æ®", "æ•°æ®åˆ†æå¸ˆ"),
        ("è¿ç»´", "Linuxè¿ç»´å·¥ç¨‹å¸ˆ"),
    ]
    for keyword, template_name in fallback_map:
        if keyword in job_name:
            matched = next((j for j in target_jobs if j.get("name") == template_name), None)
            if matched:
                cfg = dict(matched)
                cfg["name"] = job_name
                return cfg
    # æœ€ç»ˆå…œåº•ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®ä½œä¸ºé€šç”¨æ¨¡æ¿
    first = target_jobs[0]
    cfg = dict(first)
    cfg["name"] = job_name
    return cfg


def _synthetic_job_id(job_name: str, task_id: str) -> str:
    """ä»»æ„å²—ä½åä½¿ç”¨ç‹¬ç«‹ job_idï¼Œé¿å…è¦†ç›–æ¨¡æ¿é…ç½®çš„å­˜å‚¨ã€‚"""
    import re
    slug = re.sub(r"[^\w\u4e00-\u9fff]", "_", (job_name or "")[:24]).strip("_") or "unknown"
    return f"gen_{slug}_{task_id[-6:]}" if task_id else f"gen_{slug}"


@job_bp.route("/ai-generate-profile", methods=["POST"])
def ai_generate_profile():
    """
    ä½¿ç”¨AIå¤§æ¨¡å‹åˆ†æå²—ä½æ•°æ®ï¼Œç”Ÿæˆæ–°çš„å²—ä½ç”»åƒï¼ˆå¼‚æ­¥ï¼‰
    è¯·æ±‚ä½“ï¼ˆå¯¹åº”APIæ–‡æ¡£4.4ï¼‰ï¼š
      { job_name, job_descriptions: [...], sample_size }
    job_descriptions ä¸ºå‰ç«¯ä¼ å…¥çš„JDæ–‡æœ¬æ•°ç»„ï¼ˆå¯é€‰ï¼‰ï¼›
    è‹¥ä¸ä¼ ï¼Œåˆ™è‡ªåŠ¨ä»å†…éƒ¨CSVæ•°æ®é›†ä¸­æ£€ç´¢å¯¹åº”JDã€‚
    æ”¯æŒä»»æ„å²—ä½åç§°ï¼šæœªç²¾ç¡®åŒ¹é…æ—¶æŒ‰æ¨¡ç³ŠåŒ¹é…æˆ–é€šç”¨æ¨¡æ¿ç”Ÿæˆã€‚
    """
    try:
        body = request.get_json(silent=True) or {}
        job_name         = body.get("job_name")           # å•ä¸ªå²—ä½åç§°
        job_names        = body.get("job_names", [])      # æ‰¹é‡å²—ä½ï¼ˆå¯¹åº”8.2ï¼‰
        job_descriptions = body.get("job_descriptions", [])  # å‰ç«¯ä¼ å…¥JDåˆ—è¡¨ï¼ˆ4.4ï¼‰
        sample_size      = int(body.get("sample_size", 30))

        if not job_name and not job_names:
            return error_response(400, "è¯·æä¾› job_name æˆ– job_names å‚æ•°")

        service = get_job_profile_service()
        target_jobs = job_profile_conf.get("target_jobs", [])
        ts = datetime.now().strftime("%Y%m%d%H%M%S")

        if job_name:
            # â”€â”€ å•ä¸ªå²—ä½ç”Ÿæˆï¼ˆæ”¯æŒä»»æ„å²—ä½åï¼šæ¨¡ç³ŠåŒ¹é…æˆ–å…œåº•æ¨¡æ¿ï¼‰â”€â”€
            task_id = f"job_gen_{ts}_{(job_name or '')[:8]}"
            job_config = _resolve_job_config(job_name, target_jobs)
            if not job_config:
                return error_response(404, f"æœªæ‰¾åˆ°å¯ç”¨çš„å²—ä½é…ç½®ï¼ˆtarget_jobs ä¸ºç©ºï¼‰")

            # ç²¾ç¡®åŒ¹é…ï¼ˆé…ç½®ä¸­å·²æœ‰è¯¥å²—ä½åï¼‰ä¿ç•™åŸ job_idï¼›æ¨¡ç³Š/å…œåº•åŒ¹é…ç”¨ç‹¬ç«‹ job_id å­˜ç»“æœï¼Œé¿å…è¦†ç›–æ¨¡æ¿
            is_exact = any(j.get("name") == job_name for j in target_jobs)
            if not is_exact:
                job_config["job_id"] = _synthetic_job_id(job_name, task_id)
            job_config["name"] = job_name

            def _generate_single():
                cfg = dict(job_config)
                if job_descriptions:
                    cfg["external_jd_list"] = job_descriptions[:sample_size]
                profile = service.generate_profile(cfg)
                service.profiles_store[cfg["job_id"]] = profile
                from job_profile.job_profile_service import _save_profiles_store
                _save_profiles_store(service.profiles_store)
                return profile

            _run_task_async(task_id, _generate_single)

            return success_response({
                "task_id": task_id,
                "status": "processing",
                "estimated_time": 30,
                "job_name": job_name
            }, msg="AIç”»åƒç”Ÿæˆä¸­...")

        else:
            # â”€â”€ æ‰¹é‡ç”Ÿæˆï¼ˆåŒæ ·æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰â”€â”€
            task_id = f"batch_gen_{ts}"

            def _generate_batch():
                results = {}
                errors = {}
                for name in job_names:
                    cfg = _resolve_job_config(name, target_jobs)
                    if not cfg:
                        errors[name] = "æœªæ‰¾åˆ°é…ç½®"
                        continue
                    cfg["name"] = name
                    tid = f"batch_{ts}_{name[:8]}"
                    cfg["job_id"] = _synthetic_job_id(name, tid)
                    try:
                        profile = service.generate_profile(dict(cfg))
                        service.profiles_store[cfg["job_id"]] = profile
                        results[name] = cfg["job_id"]
                    except Exception as ex:
                        errors[name] = str(ex)
                from job_profile.job_profile_service import _save_profiles_store
                _save_profiles_store(service.profiles_store)
                return {"results": results, "errors": errors}

            _run_task_async(task_id, _generate_batch)

            return success_response({
                "task_id": task_id,
                "total_jobs": len(job_names),
                "status": "processing",
                "estimated_time": f"{len(job_names) * 30}ç§’"
            }, msg="æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨")

    except Exception as e:
        logger.error(f"[API] /job/ai-generate-profile å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 4.5 è·å–AIç”Ÿæˆç»“æœ
# POST /api/v1/job/ai-generate-result
# ============================================================
@job_bp.route("/ai-generate-result", methods=["POST"])
def get_ai_generate_result():
    """
    è·å–AIå²—ä½ç”»åƒç”Ÿæˆç»“æœ
    è¯·æ±‚ä½“ï¼š{ task_id }
    """
    try:
        body = request.get_json(silent=True) or {}
        task_id = body.get("task_id")

        if not task_id:
            return error_response(400, "è¯·æä¾› task_id å‚æ•°")

        if task_id not in _tasks:
            _load_persisted_tasks()
        if task_id not in _tasks:
            return error_response(404, f"ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ: {task_id}")

        task = _tasks[task_id]
        response_data = {
            "task_id": task_id,
            "status": task["status"],  # pending / processing / completed / failed
        }

        if task["status"] == "completed":
            raw = task["result"]
            # å¯¹åº”APIæ–‡æ¡£4.5å“åº”æ ¼å¼ï¼šjob_profile + ai_confidence + data_sources
            response_data["job_profile"]  = raw if isinstance(raw, dict) else raw
            response_data["ai_confidence"] = (
                raw.get("_ai_confidence", 0.88)
                if isinstance(raw, dict) else 0.88
            )
            response_data["data_sources"] = {
                "total_samples":  (raw.get("csv_sample_count", 0)
                                   if isinstance(raw, dict) else 0),
                "valid_samples":  (raw.get("csv_sample_count", 0)
                                   if isinstance(raw, dict) else 0),
                "analysis_date":  datetime.now().strftime("%Y-%m-%d"),
                "data_source":    (raw.get("data_source", "")
                                   if isinstance(raw, dict) else ""),
            }
        elif task["status"] == "failed":
            response_data["error"] = task["error"]

        return success_response(response_data)

    except Exception as e:
        logger.error(f"[API] /job/ai-generate-result å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# é¢å¤–ï¼šè·å–å®Œæ•´å²—ä½å…³è”å›¾è°±ï¼ˆå…¨å±€ï¼‰
# POST /api/v1/job/full-graph
# ============================================================
@job_bp.route("/full-graph", methods=["POST"])
def get_full_graph():
    """
    è·å–å…¨é‡å²—ä½å…³è”å›¾è°±ï¼ˆåŒ…å«æ‰€æœ‰å‚ç›´+æ¢å²—è·¯å¾„ï¼‰
    """
    try:
        graph_service = get_job_graph_service()
        graph = graph_service.get_full_graph()
        return success_response(graph)
    except Exception as e:
        logger.error(f"[API] /job/full-graph å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")


# ============================================================
# 8.2 è§¦å‘å²—ä½ç”»åƒç”Ÿæˆï¼ˆå¯¹åº”APIæ–‡æ¡£ 8.2ï¼‰
# POST /api/v1/system/generate-job-profiles
# æ³¨ï¼šåŒæ—¶ä¿ç•™ /job/batch-generate ä½œä¸ºå†…éƒ¨å…¼å®¹è·¯å¾„
# ============================================================
@job_bp.route("/batch-generate", methods=["POST"])
def _batch_generate_compat():
    """å…¼å®¹æ—§è·¯å¾„ï¼Œè½¬å‘è‡³æ ‡å‡†è·¯å¾„å¤„ç†å‡½æ•°"""
    return _do_batch_generate()


# æ ‡å‡†è·¯å¾„ï¼ˆå¯¹åº”APIæ–‡æ¡£8.2ï¼‰
from flask import current_app as _app

def _register_system_route(app):
    """åœ¨ app ä¸Šæ³¨å†Œ /api/v1/system è·¯ç”±ï¼ˆç”± app.py è°ƒç”¨ï¼‰"""
    @app.route("/api/v1/system/generate-job-profiles", methods=["POST"])
    def system_generate_job_profiles():
        """
        8.2 ç®¡ç†å‘˜è§¦å‘æ‰¹é‡å²—ä½ç”»åƒç”Ÿæˆï¼ˆå¯¹åº”APIæ–‡æ¡£8.2ï¼‰
        è¯·æ±‚ä½“ï¼š{ admin_id, job_names: [...], sample_size_per_job }
        admin_id ä¸ºå¿…å¡«ï¼Œæ ‡å‡†è·¯å¾„åœ¨æ­¤æ ¡éªŒæƒé™ã€‚
        """
        body = request.get_json(silent=True) or {}
        admin_id = body.get("admin_id")
        if admin_id is None:
            return error_response(400, "è¯·æä¾› admin_id å‚æ•°")
        return _do_batch_generate()


def _do_batch_generate():
    """
    æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é¢„é…ç½®å²—ä½çš„ç”»åƒï¼ˆå†…éƒ¨å®ç°ï¼Œä¸å«æƒé™æ ¡éªŒï¼‰
    ä¾›æ ‡å‡†è·¯å¾„ /system/generate-job-profiles å’Œå…¼å®¹è·¯å¾„ /job/batch-generate å…±ç”¨ã€‚
    è¯·æ±‚ä½“ï¼š{ force_regenerate }
    """
    try:
        body = request.get_json(silent=True) or {}
        force = body.get("force_regenerate", False)

        ts = datetime.now().strftime("%Y%m%d%H%M%S")
        task_id = f"batch_gen_all_{ts}"

        service = get_job_profile_service()
        target_jobs = job_profile_conf.get("target_jobs", [])

        def _generate_all():
            return service.generate_all_profiles(force_regenerate=force)

        _run_task_async(task_id, _generate_all)

        return success_response({
            "task_id": task_id,
            "total_jobs": len(target_jobs),
            "status": "processing",
            "estimated_time": f"çº¦{len(target_jobs) * 30}ç§’",
            "job_names": [j["name"] for j in target_jobs]
        }, msg="æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨")

    except Exception as e:
        logger.error(f"[API] /job/batch-generate å¼‚å¸¸: {e}", exc_info=True)
        return error_response(500, f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")
